[ { "title": "IIS", "url": "/posts/windows-iis/", "categories": "System, Windows, IIS", "tags": "system, windows, iis", "date": "2022-12-09 14:00:00 +0100", "snippet": "Generate a configuration change script from IIS Manager GUIGo to the Configuration editor, create a change and click on Generate script:Script generation from IIS Manager GUITroubleshooting failed requests using tracingFirst be sure that the role Tracing is installed:Check if the Tracing role is installedThen go to the web site level, and enable the tracing:Go to the web site levelEnable TracingThen go to a web application level, and create a tracing rule:Go to a web application levelAdd a Tracing ruleSetting a Tracing rule, step 1Setting a Tracing rule, step 2Setting a Tracing rule, step 3Tracing rule createdNow we can have xml traces and open them with a browser. Wa have access to a lot of details (ie. a bearer token):Trace details, example 1Trace details, example 2Trace details, example 3" }, { "title": "Disk commands", "url": "/posts/linux-disk/", "categories": "System, Linux", "tags": "system, linux, shell, tips, disk", "date": "2022-11-15 14:00:00 +0100", "snippet": "List information about block devicesWith lsblk (see man), we can get the list and characteristics of disks and their partitions. Example output:NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTnvme0n1 259:1 0 50G 0 disk └─nvme0n1p1 259:2 0 50G 0 part /nvme1n1 259:0 0 50G 0 diskFind a (mounted) filesystemfindmnt (see man) display a list of all mounted file systems or search for a file system. Example output:TARGET SOURCE FSTYPE OPTIONS/ /dev/nvme0n1p1 xfs rw,relatime,seclabel,attr2,inode64,noquota├─/sys sysfs sysfs rw,nosuid,nodev,noexec,relatime,seclabel│ ├─/sys/kernel/security securityfs securityfs rw,nosuid,nodev,noexec,relatime│ ├─/sys/fs/cgroup tmpfs tmpfs ro,nosuid,nodev,noexec,seclabel,mode=755│ │ ├─/sys/fs/cgroup/systemd cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd│ │ ├─/sys/fs/cgroup/cpuset cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,cpuset│ │ ├─/sys/fs/cgroup/pids cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,pids│ │ ├─/sys/fs/cgroup/net_cls,net_prio cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,net_prio,net_cls│ │ ├─/sys/fs/cgroup/freezer cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,freezer│ │ ├─/sys/fs/cgroup/cpu,cpuacct cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,cpuacct,cpu│ │ ├─/sys/fs/cgroup/perf_event cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,perf_event│ │ ├─/sys/fs/cgroup/memory cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,memory│ │ ├─/sys/fs/cgroup/hugetlb cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,hugetlb│ │ ├─/sys/fs/cgroup/blkio cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,blkio│ │ └─/sys/fs/cgroup/devices cgroup cgroup rw,nosuid,nodev,noexec,relatime,seclabel,devices│ ├─/sys/fs/pstore pstore pstore rw,nosuid,nodev,noexec,relatime│ ├─/sys/fs/selinux selinuxfs selinuxfs rw,relatime│ ├─/sys/kernel/config configfs configfs rw,relatime│ └─/sys/kernel/debug debugfs debugfs rw,relatime├─/proc proc proc rw,nosuid,nodev,noexec,relatime│ └─/proc/sys/fs/binfmt_misc systemd-1 autofs rw,relatime,fd=28,pgrp=1,timeout=0,minproto=5,maxproto=5,direct,pipe_ino=998│ └─/proc/sys/fs/binfmt_misc binfmt_misc binfmt_misc rw,relatime├─/dev devtmpfs devtmpfs rw,nosuid,seclabel,size=7957576k,nr_inodes=1989394,mode=755│ ├─/dev/shm tmpfs tmpfs rw,nosuid,nodev,seclabel│ ├─/dev/pts devpts devpts rw,nosuid,noexec,relatime,seclabel,gid=5,mode=620,ptmxmode=000│ ├─/dev/mqueue mqueue mqueue rw,relatime,seclabel│ └─/dev/hugepages hugetlbfs hugetlbfs rw,relatime,seclabel├─/run tmpfs tmpfs rw,nosuid,nodev,seclabel,mode=755│ └─/run/user/1000 tmpfs tmpfs rw,nosuid,nodev,relatime,seclabel,size=1596316k,mode=700,uid=1000,gid=1000└─/var/lib/nfs/rpc_pipefs rpc_pipefs rpc_pipefs rw,relatimeManipulate disk partition tablefdisk (see man) allows to create, delete, list partitions on a hard disk. fdisk needs administrator rights.List the partition tables for the specified devicesWith the -l option only, it will list all the partitions from all the devices:sudo fdisk -lExample output:Disk /dev/nvme1n1: 53.7 GB, 53687091200 bytes, 104857600 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/nvme0n1: 53.7 GB, 53687091200 bytes, 104857600 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x000b0d11 Device Boot Start End Blocks Id System/dev/nvme0n1p1 * 2048 104857566 52427759+ 83 LinuSpecifying a device name, it will list only the partitions related to that device:sudo fdisk -l /dev/nvme1n1Example output:Disk /dev/nvme1n1: 53.7 GB, 53687091200 bytes, 104857600 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesFull exampleCreationList disks with sudo fdisk -lDisk /dev/sda: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk /dev/sdb: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk /dev/sdc: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisklabel type: dosDisk identifier: 0x94a4803eDisk /dev/sdd: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisklabel type: dosDisk identifier: 0x032632cbDisk /dev/sde: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk /dev/sdf: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesCheck existing partitions with lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 256G 0 disksdb 8:16 0 256G 0 disk /sdc 8:32 0 256G 0 disksdd 8:48 0 256G 0 disksde 8:64 0 256G 0 disksdf 8:80 0 256G 0 diskCreate a partition on /dev/sdd with the sudo fdisk /dev/sdd commandThis is an interactive prompt: d: delete a partition n: add a new partition p: print the partition table w: write table to disk and exitSo create a partition with n, type the needed parameters and validate with w.Check existing partitions with lsblk againNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 256G 0 disksdb 8:16 0 256G 0 disk /sdc 8:32 0 256G 0 disksdd 8:48 0 256G 0 disk└─sdd1 8:49 0 256G 0 partsde 8:64 0 256G 0 disksdf 8:80 0 256G 0 diskList disks with sudo fdisk -l againDisk /dev/sda: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk /dev/sdb: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk /dev/sdc: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisklabel type: dosDisk identifier: 0x94a4803eDisk /dev/sdd: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisklabel type: dosDisk identifier: 0x032632cbDevice Boot Start End Sectors Size Id Type/dev/sdd1 2048 536870911 536868864 256G 83 LinuxDisk /dev/sde: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisk /dev/sdf: 256 GiB, 274877906944 bytes, 536870912 sectorsDisk model: Virtual DiskUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesFormat the partition with mkfs commandHere we have created the /dev/sdd1 partition, so we can use sudo mkfs /dev/sdd1 (default partition type can be ext2) or specify a partition type (like xfs) with the command sudo mkfs.xfs /dev/sdd1. file command can help to know an already formatted partition type, ie. sudo file -sL /dev/sdc1.Create a directory to mount the partition onExample sudo mkdir -p /myDirectory/subDirectory.Mount the partitionExample sudo mount /dev/sdd1 /myDirectory/subDirectory.Check the mount point with findmntTARGET SOURCE FSTYPE OPTIONS/ /dev/sdf ext4 rw,relatime,discard,errors=remount-ro,data=ordered├─/mnt/wsl tmpfs tmpfs rw,relatime├─/init tools[/init] 9p ro,relatime,dirsync,aname=tools;fmask=022,loose,access=client,trans=fd,rfd=6,wfd=6├─/dev none devtmpfs rw,nosuid,relatime,size=13073648k,nr_inodes=3268412,mode=755│ └─/dev/pts devpts devpts rw,nosuid,noexec,noatime,gid=5,mode=620,ptmxmode=000├─/sys sysfs sysfs rw,nosuid,nodev,noexec,noatime│ └─/sys/fs/cgroup tmpfs tmpfs rw,nosuid,nodev,noexec,relatime,mode=755│ ├─/sys/fs/cgroup/unified cgroup2 cgroup2 rw,nosuid,nodev,noexec,relatime,nsdelegate│ ├─/sys/fs/cgroup/cpuset cgroup cgroup rw,nosuid,nodev,noexec,relatime,cpuset│ ├─/sys/fs/cgroup/cpu cgroup cgroup rw,nosuid,nodev,noexec,relatime,cpu│ ├─/sys/fs/cgroup/cpuacct cgroup cgroup rw,nosuid,nodev,noexec,relatime,cpuacct│ ├─/sys/fs/cgroup/blkio cgroup cgroup rw,nosuid,nodev,noexec,relatime,blkio│ ├─/sys/fs/cgroup/memory cgroup cgroup rw,nosuid,nodev,noexec,relatime,memory│ ├─/sys/fs/cgroup/devices cgroup cgroup rw,nosuid,nodev,noexec,relatime,devices│ ├─/sys/fs/cgroup/freezer cgroup cgroup rw,nosuid,nodev,noexec,relatime,freezer│ ├─/sys/fs/cgroup/net_cls cgroup cgroup rw,nosuid,nodev,noexec,relatime,net_cls│ ├─/sys/fs/cgroup/perf_event cgroup cgroup rw,nosuid,nodev,noexec,relatime,perf_event│ ├─/sys/fs/cgroup/net_prio cgroup cgroup rw,nosuid,nodev,noexec,relatime,net_prio│ ├─/sys/fs/cgroup/hugetlb cgroup cgroup rw,nosuid,nodev,noexec,relatime,hugetlb│ ├─/sys/fs/cgroup/pids cgroup cgroup rw,nosuid,nodev,noexec,relatime,pids│ └─/sys/fs/cgroup/rdma cgroup cgroup rw,nosuid,nodev,noexec,relatime,rdma├─/proc proc proc rw,nosuid,nodev,noexec,noatime│ └─/proc/sys/fs/binfmt_misc binfmt_misc binfmt_misc rw,relatime├─/run none tmpfs rw,nosuid,noexec,noatime,mode=755│ ├─/run/lock none tmpfs rw,nosuid,nodev,noexec,noatime│ ├─/run/shm none tmpfs rw,nosuid,nodev,noatime│ └─/run/user none tmpfs rw,nosuid,nodev,noexec,noatime,mode=755├─/usr/lib/wsl/drivers drivers 9p ro,nosuid,nodev,noatime,dirsync,aname=drivers;fmask=222;dmask=222,mmap,access=client,msize=65536,trans=fd,rfd=4,wfd=4├─/usr/lib/wsl/lib lib 9p ro,nosuid,nodev,noatime,dirsync,aname=lib;fmask=222;dmask=222,mmap,access=client,msize=65536,trans=fd,rfd=4,wfd=4├─/mnt/c C:\\ 9p rw,noatime,dirsync,aname=drvfs;path=C:\\;uid=0;gid=0;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=8,wfd=8├─/mnt/g G:\\ 9p rw,noatime,dirsync,aname=drvfs;path=G:\\;uid=0;gid=0;symlinkroot=/mnt/,mmap,access=client,msize=65536,trans=fd,rfd=8,wfd=8└─/myDirectory/subDirectory /dev/sdd1 ext2 rw,relatime,stripe=4DeletionUnmount the partitition with umountsudo umount /dev/sdd1Delete the directory it’s mounted onsudo -Rf /myDirectory/subDirectoryDelete the partition with fdiskDelete the partition with d and validate with w.Every step can be checked with the previous given commands.Space usage with df and duFile system disk space usage with df. -k for block size, -h for human readable:df -kFilesystem 1K-blocks Used Available Use% Mounted ondevtmpfs 24588420 0 24588420 0% /devtmpfs 24607388 8 24607380 1% /dev/shmtmpfs 24607388 2516124 22091264 11% /runtmpfs 24607388 0 24607388 0% /sys/fs/cgroup/dev/mapper/vg00-lvroot 2086912 85664 2001248 5% //dev/mapper/vg00-lvusr 4184064 2301672 1882392 56% /usrtmpfs 24607388 8 24607380 1% /tmpdf -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 24G 0 24G 0% /devtmpfs 24G 8.0K 24G 1% /dev/shmtmpfs 24G 2.4G 22G 11% /runtmpfs 24G 0 24G 0% /sys/fs/cgroup/dev/mapper/vg00-lvroot 2.0G 84M 2.0G 5% //dev/mapper/vg00-lvusr 4.0G 2.2G 1.8G 56% /usrtmpfs 24G 8.0K 24G 1% /tmpFile space usage with du. -k for block size, -h for human readable, -a for counts for all files, not just directories:df -h148K ./.ssh0 ./.ansible/tmp0 ./.ansibledf -ha4.0K ./.bash_logout4.0K ./.bash_profile4.0K ./.bashrc4.0K ./.ssh/authorized_keys4.0K ./.ssh/authorized_keys24.0K ./.ssh/authorized_keys3148K ./.ssh8.0K ./.bash_history0 ./.ansible/tmp0 ./.ansible" }, { "title": "Regex", "url": "/posts/dev-misc-regex/", "categories": "Development, Regex", "tags": "development, regex", "date": "2022-11-04 10:00:00 +0100", "snippet": "Match a line that does not contain a wordExample with “it” word:^((?!it).)*$Sources: stackoverflow regex101" }, { "title": "French definitions", "url": "/posts/misc-french-definitions/", "categories": "Definitions, French, Misc", "tags": "definitions, french, misc", "date": "2022-11-03 17:00:00 +0100", "snippet": "French definitions Quantum: Quantité déterminée, montant dans une répartition, proportion d’une grandeur dans un ensemble." }, { "title": "French acronyms", "url": "/posts/misc-french-acronyms/", "categories": "Acronyms, French, Misc", "tags": "acronyms, french, misc", "date": "2022-10-25 09:00:00 +0200", "snippet": "French acronyms AGE: Assemblée Générale Extraordinaire (ou Assemblée Générale Spéciale). Réunion des actionnaires d’une société en vue de prendre des décisions la concernant. Elle n’a ni fréquence spécifique, ni délai de tenue. AGO: Assemblée Générale Oordinaire (ou Assemblée Générale Annuelle). Réunion en assemblée des associés ou actionnaires d’une société. Elle se tient au minimum une fois par an, dans les six mois suivant la clôture de l’exercice comptable. Les actionnaires prennent ainsi part à son fonctionnement et à son contrôle. BNC: Bénéfices Non Commerciaux. Ils sont une catégorie dans laquelle rentrent principalement les revenus tirés d’une activité libérale. CCA: Compte Courant d’Associés. Somme versée par un associé dans la trésorerie de son entreprise. Cette somme peut être soit directement versée par l’associé soit correspondre à une créance envers l’associé, et laissée à la disposition de l’entreprise. CCI: Chambre de Commerce et d’Industrie. Organismes chargés de représenter les intérêts des entreprises commerciales, industrielles et de services d’une zone géographique et de leur apporter certains services. ESN: Entreprise de Services du Numérique, anciennement Société de Srvices en Ingénierie Informatique (SSII ou SS2I). Société de services experte dans le domaine des nouvelles technologies et de l’informatique. TJM: Taux Journalier Moyen. Montant qui sera facturé à la société cliente pour une journée de prestation." }, { "title": "Products", "url": "/posts/misc-products/", "categories": "Products, Misc", "tags": "products, misc", "date": "2022-09-30 09:00:00 +0200", "snippet": "ProductsMisc VMware ESXi (formerly ESX): VMware hypervisor.Software configuration management tools Ansible Progress Chef (formerly Chef) PuppetSee comparison of open-source configuration management software." }, { "title": "Perl arguments", "url": "/posts/perl-arguments/", "categories": "Development, Perl", "tags": "development, perl, arguments", "date": "2022-09-02 09:00:00 +0200", "snippet": "ArgumentsEasiest way to treat arguments in Perl is with the Getopt::Long native module.It works like this: Declaration of the target variable(s) that will contain the argument(s) value(s), ie.:my ($targetVariable) = ();# Ormy ($targetVariable1, $targetVariable2, @targetVariable3) = (); Argument declaration in the call to the GetOptions method, with the format 'argumentName[|argumentAlias]=argumentType' =&gt; \\$targetVariable Arguments types are: i for an integer s for a string nothing for a flag Arguments can be used with - or --, ie. -argumentName or --argumentName# First import the moduleuse Getopt::Long; # Then declare the variablesmy ($targetVariable1, $targetVariable2, @targetVariable3, $doDebug) = ();GetOptions( 'fooArg|f=i' =&gt; \\$targetVariable1, 'barArg=s' =&gt; \\$targetVariable2, 'bazArg|b=s' =&gt; \\@targetVariable3, 'debug' =&gt; \\$doDebug);# Check if an argument has been givenprint \"fooArg is mandatory!\" if (!defined $targetVariable1);# Flag usage if not given$doDebug = 0 if (!defined $doDebug);Example of a call to this script:./myScript.pl --fooArg 10 -barArg TOTO --bazArg BAZ_1 --b BAZ_2 -bazArg BAZ_3 --debug" }, { "title": "Definitions", "url": "/posts/misc-definitions/", "categories": "Definitions, Misc", "tags": "definitions, misc", "date": "2022-09-01 09:00:00 +0200", "snippet": "Definitions Ballooning: When an hypervisor lacks of RAM, it can take free RAM from a VM, inflating a “fake” balloon making the VM think it lacks of memory in order to make it swap and so let the real RAM free for the hypervisor Wikipédia. On-premises: On-premises software (abbreviated to on-prem) is installed and runs on computers on the premises of the person or organization using the software. OAuth(fr): It is an open standard for access delegation, commonly used as a way for internet users to grant websites or applications access to their information on other websites but without giving them the passwords. OpenID(fr): It’s an open standard and decentralized authentication protocol promoted by the non-profit OpenID Foundation. It allows users to be authenticated by co-operating sites (known as relying parties, or RP) using a third-party identity provider (IDP) service, eliminating the need for webmasters to provide their own ad hoc login systems, and allowing users to log in to multiple unrelated websites without having to have a separate identity and password for each. Private cloud: Decicated Cloud. Quick win: A small change that allows to quickly and simply obtain a gain (oie. financial). SecOps: Management method that made the link between security and IT operations (exploitation) teams. " }, { "title": "Perl references", "url": "/posts/perl-references/", "categories": "Development, Perl", "tags": "development, perl, references", "date": "2022-08-30 09:00:00 +0200", "snippet": "ReferencesA reference is a scalar that hosts the location of another value (that can be another scalar, an hash or an array). References are the best way to pass an array or a hash to a sub.Create a referenceTo create a reference, just add a '\\' before an existing item:my $scalar;my @array;my %hash;my $referenceScalar = \\$scalar;my $referenceArray = \\@array;my $referenceHash = \\%hash;# Named subsub MySub { return \"Foo\"; }my $referenceSub = \\&amp;MySub;# \"Anonymous\" sub referencemy $referenceAnonymousSub = { return \"Bar\"; };DereferenceJust add the type’s prefix before the reference, ie. $, @, % or &amp;:my $scalar;my @array;my %hash;my $referenceScalar = \\$scalar;my $referenceArray = \\@array;my $referenceHash = \\%hash;my $referenceAnonymousSub = sub { return \"Bar\" };my $dereferencedScalar = $$referenceScalar;my @dereferencedArray = @$referenceArray;my %dereferencedHash = %$referenceHash;# Call this sub&amp;$referenceAnonymousSub();Know the reference’s typeWith the keyword ref. Ie. with previous example:print ref($referenceScalar), \"\\n\";print ref($referenceArray), \"\\n\";print ref($referenceHash), \"\\n\";print ref($referenceAnonymousSub), \"\\n\";Output is:SCALARARRAYHASHCODE" }, { "title": "PowerShell strings operations", "url": "/posts/powershell-strings/", "categories": "Development, PowerShell", "tags": "development, powershell, strings", "date": "2022-08-29 09:00:00 +0200", "snippet": "Grep likeSimple grepWith the Select-String cmdlet. Ie.:Select-String \"Pattern to look for\" \"C:\\myDirectory\\*.txt\"Output is like:C:\\myDirectory\\one.txt:AAA Pattern to look for BBBC:\\myDirectory\\two.txt:AAA Pattern to look for BBBWith a lines count (wc -l equivalent)With the Measure-Object cmdlet. Ie.:Select-String \"Pattern to look for\" \"C:\\myDirectory\\*.txt\" | Measure-Object -LineOutput is like:Lines Words Characters Property----- ----- ---------- -------- 836 1698Select only the lines count with Select-Object -ExpandProperty argument:Select-String \"Pattern to look for\" \"C:\\myDirectory\\*.txt\" | Measure-Object -Line | Select-Object -ExpandProperty LinesOutput is like:836 1698Grep with regex extraction on outputWith the Select-String cmdlet again. Ie.:$regex = [regex]\"^.*Foo_Bar(.*?)Baz_Qux$\";# We get every match in each line with -AllMatches (without it, it will get the first match in each line)Select-String -Path \"C:\\myDirectory\\*.txt\" $regex -AllMatches | Foreach-Object {$_.Matches} | Foreach-Object { $currentNeededPart = $_.Groups[1].Value;};" }, { "title": "PowerShell hashes", "url": "/posts/powershell-hashes/", "categories": "Development, PowerShell", "tags": "development, powershell, hashes", "date": "2022-08-29 09:00:00 +0200", "snippet": "Create a hash$hash = @{};Add a key$hash.Add(\"newKey\", 1);Modify an existing value$hash[\"existingKey\"] = 2;Check if a key already existsWith Contains:$keyToTest = \"keyToTest\";if ($hash.ContainsKey($keyToTest)) { $hash[$keyToTest]++;}else { $hash.Add($keyToTest, 1);}Loop on the hash in an ordered wayWith getEnumerator, ie. on the keys:$hash.getEnumerator() | Sort-Object Key | foreach { Write-Host -BackgroundColor Black -ForegroundColor Magenta ($_.key + \";\" + $_.value);}" }, { "title": "PowerShell dates", "url": "/posts/powershell-dates/", "categories": "Development, PowerShell", "tags": "development, powershell, dates", "date": "2022-08-29 09:00:00 +0200", "snippet": "Get the number of days in a month thanks to its numberWith DaysInMonth:$currentMonth = 7$currentLastDay = [DateTime]::DaysInMonth([DateTime]::Now.Year, $currentMonth);# $currentLastDay is 31Get a month’s name thanks to its numberWith GetMonthName:$currentMonth = 7(Get-Culture).DateTimeFormat.GetMonthName($currentMonth)Output is:July" }, { "title": "Perl strings", "url": "/posts/perl-strings/", "categories": "Development, Perl", "tags": "development, perl, strings", "date": "2022-08-29 09:00:00 +0200", "snippet": "Substringsubstr(EXPR,OFFSET,LENGTH,REPLACEMENT)With: EXPR: the string to substring OFFSET: the index to start at. If OFFSET is negative, starts that far back from the end of the string LENGTH: the length to substring (optional). If LENGTH is negative, leaves that many characters off the end of the string REPLACEMENT: replacement string (optional)Classic way:$string = \"ABCDEFG\";substr($string, 3) # Starts at index 3 to the end, so \"DEFG\"substr($string, -2) # Negative index here means \"start 2 characters back from the end\", so \"FG\"substr($string, 3, 2) # Starts at index 3, then takes 2 characters, so \"DE\"substr($string, 3, -1) # Starts at index 3, then to \"1 character back from the end\", so \"DEF\"CPAN sourceIndex/rindexindex returns the first occurence’s index of a string in another one, -1 if it does not exist. rindex does the same except it returns the last index.index(STR,SUBSTR,POSITION)rindex(STR,SUBSTR,POSITION)With: STR: the string to search in SUBSTR: the string to look after in the other one POSITION: the position to start the search at. If POSITION is omitted, starts searching from the beginning of the stringmy $string = \"ABCABCABC\";index($string, \"A\") # 0index($string, \"X\") # -1index($string, \"A\", 2) # 3rindex($string, \"A\") # 6Sources: CPAN index CPAN rindexSplitmy $string = \"a,b,c,d\";@myArray = split /,/, $string;# myArray contains (\"a\", \"b\", \"c\", \"d\")Source: splitJoinmy $separator = ',';my @array = (\"d\", \"e\", \"f\");my $joined1 = join($separator, \"a\", \"b\", \"c\");my $joined2 = join($separator, @array);Source: join" }, { "title": "Perl operators", "url": "/posts/perl-operators/", "categories": "Development, Perl", "tags": "development, perl, operators", "date": "2022-08-29 09:00:00 +0200", "snippet": "Comparison operators Type Numeric String Equality == eq Difference != ne Difference &lt;=&gt; cmp Less than &lt; lt Greater than &gt; gt Less than or equal &lt;= le Greater than or equal &gt;= ge &lt;=&gt; and cmp return 1 if left value is greater than right value, 0 if left value equals right value and -1 if left value is lower than right value.Logical operators Type Operator and &amp;&amp; or || " }, { "title": "Perl loops", "url": "/posts/perl-loops/", "categories": "Development, Perl", "tags": "development, perl, loops", "date": "2022-08-29 09:00:00 +0200", "snippet": "Loops with a defined indexOld school way using a defined index:my @array = (1..100);my $lastIndex = $#array; # or (scalar @array) - 1for (my $i = 0; $i &lt;= $lastIndex; $i++){ print(\"Current value is $array[$i] \\n\");}Loops without a defined indexEasier way with a defined value:my @array = (1..100);for my $currentValue (@array){ print(\"Current value is $currentValue\\n\");}With non defined value (automatic value is $_):my @array = (1..100);for (@array){ print(\"Current value is $_\\n\");}For each loopSame as for, with or without a defined value:my @array = (1..100);foreach (@array){ print(\"Current value is $_\\n\");}# Orforeach my $currentValue (@array){ print(\"Current value is $currentValue\\n\");}" }, { "title": "Perl hashes", "url": "/posts/perl-hashes/", "categories": "Development, Perl", "tags": "development, perl, hashes", "date": "2022-08-29 09:00:00 +0200", "snippet": "HashesCreationEmpty:my %hash = ();With elements, either:my %hash = ();$hash{'Foo'} = 1;$hash{'Bar'} = 2;$hash{'Baz'} = 3;Or:my %hash = ( 'Foo' =&gt; 1, 'Bar' =&gt; 2, 'Baz' =&gt; 3)Access to a valueprint \"Foo value is $hash{'Foo'}\\n\";Access to keys or valuesWith keys or values keywords:my @hashKeys = keys %hash;my @hashValues = values %hash;Another usage example:foreach my $currentHashKey (keys %hash) { # ...}Check if a value existsWith exists keyword:my $keyToTest = 'Foo';if (exists($hash{$keyToTest})) { print \"$keyToTest exists!\\n\";}Get the hash sizeSimply by getting the scalar that belong to the keys or the values:my @hashKeys = keys %hash;my @hashSize = @hashKeys;Add or remove element to an existing hashAdd an element:my %hash = ( 'Foo' =&gt; 1, 'Bar' =&gt; 2, 'Baz' =&gt; 3)# Adding a new element$hash{'Qux'} = 4;Remove an element withe the delete keyword:my %hash = ( 'Foo' =&gt; 1, 'Bar' =&gt; 2, 'Baz' =&gt; 3)# Adding a new elementdelete $hash{'Bar'};Complex elements in a hashMultidimensional hash:# Init with valuemy %hash = { 'a key' =&gt; { name =&gt; 'A name', intValue =&gt; 1, somethingElse =&gt; 'dummy' }};my $key = 'another key';$hash{$key} = { name =&gt; 'Another name', intValue =&gt; 2, somethingElse =&gt; 'dummy'};Get a multidimensional hash value:print \"A name is: $hash{$key}{name}\\n\";Set a multidimensional hash value:$hash{$key}-&gt;{name} = 'A new name!';Hash in a hash with an array element, must be elgobed in @{}:my @array = (7, 8, 9);@{$hash{$key}{subHashArray}} = @array;foreach my $arrayItem (@{$hash{$key}{subHashArray}}) { print \"$arrayItem\\n\";}" }, { "title": "Perl arrays", "url": "/posts/perl-arrays/", "categories": "Development, Perl", "tags": "development, perl, arrays", "date": "2022-08-29 09:00:00 +0200", "snippet": "Arraysmy @array = qw(\"aa\" \"bb\" \"cc\");# To get the lengthmy $length = @array;$length = scalar @array;$length = $#array + 1;$# gives the array’s last index (-1 if the array is empty), so $#array in this case and so $#array + 1 also gives its length. For a reference to an array, ie. $arrayReference, don’t forget the reference’s $ to have the last index, so $#$arrayReference.To check if an array is defined, just do an if:if (@array) { # ...} Check if a value exist in an arrayif (grep { $_ eq \"myValue\"} @array) {}Range valueWith .. ie. here from 1 to 100:my @array = (1..100);Add an item at the endWith push:my @array = qw(\"aa\" \"bb\" \"cc\");push @array, \"dd\";# @array is (\"aa\", \"bb\", \"cc\", \"dd\")my @anotherArray = qw(\"ee\" \"ff\");push @array, @anotherArray;# @array is (\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff)Remove the last itemWith pop:my @array = qw(\"aa\" \"bb\" \"cc\");# pop removes and returns the last itemmy $popped = pop @array;# $popped is \"cc\", @array is (\"aa\", \"bb\")Add an item at the beginningWith unshift:my @array = qw(\"aa\" \"bb\" \"cc\");unshift @array, \"zz\";# @array is (\"zz\", \"aa\", \"bb\", \"cc\")my @anotherArray = qw(\"xx\" \"yy\");push @array, @anotherArray;# @array is (\"xx\", \"yy\", \"zz\", \"aa\", \"bb\", \"cc\")Remove the first itemWith shift:my @array = qw(\"aa\" \"bb\" \"cc\");# shift removes and returns the first itemmy $shifted = shift @array;# $shifted is \"aa\", @array is (\"bb\", \"cc\")" }, { "title": "Logins and users", "url": "/posts/tsql-logins-and-users/", "categories": "Development, T-SQL", "tags": "development, t-sql, sqlserver, database, login, user", "date": "2022-07-26 09:00:00 +0200", "snippet": "Create loginCREATE LOGIN [myLogin] WITH PASSWORD=N'myPassword', DEFAULT_DATABASE=[master], DEFAULT_LANGUAGE=[us_english], CHECK_EXPIRATION=ON, CHECK_POLICY=ONGOCreate userCREATE USER [myUser] FOR LOGIN [myLogin]Transfer logins and passwords between instancesWith sp_help_revlogin:EXEC sp_help_revloginGOIt transfers all logins and users, needed rights, etc.See given database “orphan” users (not linked to a user - perhaps deleted)With sp_change_users_login:USE [myDatabase]EXEC sp_change_users_login 'Report';Orphan users can be linked back with an alterUSE [myDatabase]ALTER USER [myOrphanUser] WITH LOGIN = [myExistingLogin];" }, { "title": "Excel", "url": "/posts/misc-excel/", "categories": "Excel, Misc", "tags": "excel, misc", "date": "2022-07-18 09:00:00 +0200", "snippet": "New line in CONCAT or other functionJust use the character that belongs to the number 10 with CHAR function, ie. with CONCAT:CONCAT(\"NEW\";CHAR(10);\"LINE\");Output:NEWLINEFunctions EN/FR translations Function EN FR Strings concatenation CONCAT CONCAT Get a character specified by a number CHAR CAR Functions names translated" }, { "title": "JFrog Artifactory", "url": "/posts/tools-artifactory/", "categories": "Tools, Artifactory, cURL", "tags": "tools, artifactory, curl", "date": "2022-07-12 15:00:00 +0200", "snippet": "Main documentationHereDeploy a fileWith basic authenticationWith the: -u for the user -X PUT argument -T argumentcurl -u &lt;USER&gt;:&lt;PASSWORD&gt; -X PUT \"https://artifactory.myDomain.com/artifactory/myFolder/destinationFile.txt\" -T \"pathTo\\sourceFile.txt\"Or:curl -u &lt;USER&gt;:&lt;ARTIFACTORY_TOKEN&gt; -X PUT \"https://artifactory.myDomain.com/artifactory/myFolder/destinationFile.txt\" -T \"pathTo\\sourceFile.txt\"With header authenticationWith the -H for: Either the bearer Authorization header:curl -H \"Authorization: Bearer &lt;BEARER_TOKEN&gt;\" -X PUT \"https://artifactory.myDomain.com/artifactory/myFolder/destinationFile.txt\" -T \"pathTo\\sourceFile.txt\" r the JFrog Artifactory X-JFrog-Art-Api header:curl -H \"X-JFrog-Art-Api: &lt;ARTIFACTORY_TOKEN&gt;\" -X PUT \"https://artifactory.myDomain.com/artifactory/myFolder/destinationFile.txt\" -T \"pathTo\\sourceFile.txt\"Download a fileWith basic authenticationWith the: -u for the user -o argument for the outputcurl -u &lt;USER&gt;:&lt;PASSWORD&gt; \"https://artifactory.myDomain.com/artifactory/myFolder/myFile.txt\" -o \"myLocalPath/myFile.txtOr:curl -u &lt;USER&gt;:&lt;ARTIFACTORY_TOKEN&gt; \"https://artifactory.myDomain.com/artifactory/myFolder/myFile.txt\" -o \"myLocalPath/myFile.txtWith header authenticationWith the -H for: Either the bearer Authorization header:curl -H \"Authorization: Bearer &lt;BEARER_TOKEN&gt;\" \"https://artifactory.myDomain.com/artifactory/myFolder/myFile.txt\" -o \"myLocalPath/myFile.txt Or the JFrog Artifactory X-JFrog-Art-Api header:curl -H \"X-JFrog-Art-Api: &lt;ARTIFACTORY_TOKEN&gt;\" \"https://artifactory.myDomain.com/artifactory/myFolder/myFile.txt\" -o \"myLocalPath/myFile.txtAdd a checksumWith the X-Checksum-&lt;ALGORITHM&gt; header, ie. X-Checksum-MD5 or X-Checksum-SHA1:curl -H \"X-JFrog-Art-Api: &lt;ARTIFACTORY_TOKEN&gt;\" -X PUT \"https://artifactory.myDomain.com/artifactory/myFolder/destinationFile.txt\" -T \"pathTo\\sourceFile.txt\" -H \"X-Checksum-MD5:F6367DBFA4932A601A753D1E4DD381D1\" -H \"X-Checksum-SHA1:2F11CBD40205FF68205894AD8A02A5EB0C94DEA0\"Delete a fileRemark: use the -Local version of the folder.With basic authenticationThen use: -u for the user -X DELETE argumentcurl -u &lt;USER&gt;:&lt;PASSWORD&gt; -X DELETE \"https://artifactory.myDomain.com/artifactory/myFolder-Local/myFile.txt\"Or:curl -u &lt;USER&gt;:&lt;ARTIFACTORY_TOKEN&gt; -X DELETE \"https://artifactory.myDomain.com/artifactory/myFolder-Local/myFile.txt\"It should return a 204 code.With header authenticationWith the -H for: Either the bearer Authorization header:curl -H \"Authorization: Bearer &lt;BEARER_TOKEN&gt;\" -X DELETE \"https://artifactory.myDomain.com/artifactory/myFolder-Local/myFile.txt\" Or the JFrog Artifactory X-JFrog-Art-Api header:curl -H \"X-JFrog-Art-Api: &lt;ARTIFACTORY_TOKEN&gt;\" -X DELETE \"https://artifactory.myDomain.com/artifactory/myFolder-Local/myFile.txt\"" }, { "title": "T-SQL development", "url": "/posts/t-sql-development/", "categories": "Development, T-SQL", "tags": "development, t-sql, sqlserver, database", "date": "2022-07-08 09:00:00 +0200", "snippet": "Get an ID from a labelIe. with the given table:CREATE TABLE [Dummy]( [Id] [numeric](18, 0) IDENTITY(1,1) NOT NULL, [Label] [nvarchar](32) NOT NULLGet the ID in a single variable with the exact label:DECLARE @tempId AS NUMERIC(18,0)-- Parentheses are mandatorySET @tempId = (SELECT [Id] FROM [Dummy] WHERE [Label] = 'ExactLabel')Get single values from a select that return a unique lineWith previous table example:DECLARE @tempId AS NUMERIC(18,0)DECLARE @tempLabel AS NVARCHAR(32)-- Parentheses are mandatorySELECT @tempId = [Id], @tempLabel = [Label] FROM [Dummy] WHERE [Label] = 'ExactLabel'" }, { "title": "Desired State Configuration", "url": "/posts/windows-dsc/", "categories": "System, DSC", "tags": "system, dsc, tips", "date": "2022-07-06 15:00:00 +0200", "snippet": "Desired State Configuration a.k.a. DSCUseful links DSC home page GitHub custom modules home page xWebAdministration moduleList DSC resources present on the computerWith Get-DscResource cmdlet:Get-DscResourceOutput:ImplementedAs Name ModuleName Version Properties------------- ---- ---------- ------- ----------Binary File {DestinationPath, Attributes, Ch...Binary SignatureValidation {SignedItemType, TrustedStorePath}PowerShell DefaultGatewayAddress NetworkingDsc 8.2.0 {AddressFamily, InterfaceAlias, ...PowerShell DnsClientGlobalSetting NetworkingDsc 8.2.0 {IsSingleInstance, DependsOn, De...PowerShell DnsConnectionSuffix NetworkingDsc 8.2.0 {ConnectionSpecificSuffix, Inter...PowerShell DnsServerAddress NetworkingDsc 8.2.0 {AddressFamily, InterfaceAlias, ...PowerShell Firewall NetworkingDsc 8.2.0 {Name, Action, Authentication, D...PowerShell FirewallProfile NetworkingDsc 8.2.0 {Name, AllowInboundRules, AllowL...PowerShell HostsFile NetworkingDsc 8.2.0 {HostName, DependsOn, Ensure, IP...PowerShell IPAddress NetworkingDsc 8.2.0 {AddressFamily, InterfaceAlias, ...PowerShell IPAddressOption NetworkingDsc 8.2.0 {IPAddress, DependsOn, PsDscRunA...PowerShell NetAdapterAdvancedProp... NetworkingDsc 8.2.0 {NetworkAdapterName, RegistryKey...PowerShell NetAdapterBinding NetworkingDsc 8.2.0 {ComponentId, InterfaceAlias, De...PowerShell NetAdapterLso NetworkingDsc 8.2.0 {Name, Protocol, State, DependsO...PowerShell NetAdapterName NetworkingDsc 8.2.0 {NewName, DependsOn, DriverDescr...PowerShell NetAdapterRdma NetworkingDsc 8.2.0 {Name, DependsOn, Enabled, PsDsc...PowerShell NetAdapterRsc NetworkingDsc 8.2.0 {Name, Protocol, State, DependsO...PowerShell NetAdapterRss NetworkingDsc 8.2.0 {Enabled, Name, DependsOn, PsDsc...PowerShell NetAdapterState NetworkingDsc 8.2.0 {Name, State, DependsOn, PsDscRu...PowerShell NetBios NetworkingDsc 8.2.0 {InterfaceAlias, Setting, Depend...PowerShell NetConnectionProfile NetworkingDsc 8.2.0 {InterfaceAlias, DependsOn, IPv4...PowerShell NetIPInterface NetworkingDsc 8.2.0 {AddressFamily, InterfaceAlias, ...PowerShell NetworkTeam NetworkingDsc 8.2.0 {Name, TeamMembers, DependsOn, E...PowerShell NetworkTeamInterface NetworkingDsc 8.2.0 {Name, TeamName, DependsOn, Ensu...PowerShell ProxySettings NetworkingDsc 8.2.0 {IsSingleInstance, AutoConfigURL...PowerShell Route NetworkingDsc 8.2.0 {AddressFamily, DestinationPrefi...PowerShell WaitForNetworkTeam NetworkingDsc 8.2.0 {Name, DependsOn, PsDscRunAsCred...PowerShell WinsServerAddress NetworkingDsc 8.2.0 {InterfaceAlias, Address, Depend...PowerShell WinsSetting NetworkingDsc 8.2.0 {IsSingleInstance, DependsOn, En...PowerShell PackageManagement PackageManagement 1.0.0.1 {Name, AdditionalParameters, Dep...PowerShell PackageManagementSource PackageManagement 1.0.0.1 {Name, ProviderName, SourceUri, ...PowerShell Archive PSDesiredStateConfiguration 1.1 {Destination, Path, Checksum, Cr...PowerShell Environment PSDesiredStateConfiguration 1.1 {Name, DependsOn, Ensure, Path...}PowerShell Group PSDesiredStateConfiguration 1.1 {GroupName, Credential, DependsO...Composite GroupSet PSDesiredStateConfiguration 1.1 {DependsOn, PsDscRunAsCredential...Binary Log PSDesiredStateConfiguration 1.1 {Message, DependsOn, PsDscRunAsC...PowerShell Package PSDesiredStateConfiguration 1.1 {Name, Path, ProductId, Argument...Composite ProcessSet PSDesiredStateConfiguration 1.1 {DependsOn, PsDscRunAsCredential...PowerShell Registry PSDesiredStateConfiguration 1.1 {Key, ValueName, DependsOn, Ensu...PowerShell Script PSDesiredStateConfiguration 1.1 {GetScript, SetScript, TestScrip...PowerShell Service PSDesiredStateConfiguration 1.1 {Name, BuiltInAccount, Credentia...Composite ServiceSet PSDesiredStateConfiguration 1.1 {DependsOn, PsDscRunAsCredential...PowerShell User PSDesiredStateConfiguration 1.1 {UserName, DependsOn, Descriptio...PowerShell WaitForAll PSDesiredStateConfiguration 1.1 {NodeName, ResourceName, Depends...PowerShell WaitForAny PSDesiredStateConfiguration 1.1 {NodeName, ResourceName, Depends...PowerShell WaitForSome PSDesiredStateConfiguration 1.1 {NodeCount, NodeName, ResourceNa...PowerShell WindowsFeature PSDesiredStateConfiguration 1.1 {Name, Credential, DependsOn, En...Composite WindowsFeatureSet PSDesiredStateConfiguration 1.1 {DependsOn, PsDscRunAsCredential...PowerShell WindowsOptionalFeature PSDesiredStateConfiguration 1.1 {Name, DependsOn, Ensure, LogLev...Composite WindowsOptionalFeatureSet PSDesiredStateConfiguration 1.1 {DependsOn, PsDscRunAsCredential...PowerShell WindowsPackageCab PSDesiredStateConfiguration 1.1 {Ensure, Name, SourcePath, Depen...PowerShell WindowsProcess PSDesiredStateConfiguration 1.1 {Arguments, Path, Credential, De...PowerShell WebApplicationHandler xwebadministration 3.2.0 {Name, Path, AllowPathInfo, Depe...PowerShell xIisFeatureDelegation xwebadministration 3.2.0 {Filter, OverrideMode, Path, Dep...PowerShell xIisHandler xwebadministration 3.2.0 {Ensure, Name, DependsOn, PsDscR...PowerShell xIisLogging xwebadministration 3.2.0 {LogPath, DependsOn, LogCustomFi...PowerShell xIisMimeTypeMapping xwebadministration 3.2.0 {ConfigurationPath, Ensure, Exte...PowerShell xIisModule xwebadministration 3.2.0 {Name, Path, RequestPath, Verb...}PowerShell xSslSettings xwebadministration 3.2.0 {Bindings, Name, DependsOn, Ensu...PowerShell xWebApplication xwebadministration 3.2.0 {Name, PhysicalPath, WebAppPool,...PowerShell xWebAppPool xwebadministration 3.2.0 {Name, autoShutdownExe, autoShut...PowerShell xWebAppPoolDefaults xwebadministration 3.2.0 {IsSingleInstance, DependsOn, Id...PowerShell xWebConfigKeyValue xwebadministration 3.2.0 {ConfigSection, Key, WebsitePath...PowerShell xWebConfigProperty xwebadministration 3.2.0 {Filter, PropertyName, WebsitePa...PowerShell xWebConfigPropertyColl... xwebadministration 3.2.0 {CollectionName, Filter, ItemKey...PowerShell xWebSite xwebadministration 3.2.0 {Name, ApplicationPool, Applicat...PowerShell xWebSiteDefaults xwebadministration 3.2.0 {IsSingleInstance, AllowSubDirCo...PowerShell xWebVirtualDirectory xwebadministration 3.2.0 {Name, PhysicalPath, WebApplicat...Get a single DSC module’s resources detailsWith Get-DscResource cmdlet and the -Module argument:Get-DscResource -Module xWebAdministrationOutput:ImplementedAs Name ModuleName Version Properties------------- ---- ---------- ------- ----------PowerShell WebApplicationHandler xwebadministration 3.2.0 {Name, Path, AllowPathInfo, DependsOn...}PowerShell xIisFeatureDelegation xwebadministration 3.2.0 {Filter, OverrideMode, Path, DependsOn...}PowerShell xIisHandler xwebadministration 3.2.0 {Ensure, Name, DependsOn, PsDscRunAsCredential}PowerShell xIisLogging xwebadministration 3.2.0 {LogPath, DependsOn, LogCustomFields, LogFlags...}PowerShell xIisMimeTypeMapping xwebadministration 3.2.0 {ConfigurationPath, Ensure, Extension, MimeType...PowerShell xIisModule xwebadministration 3.2.0 {Name, Path, RequestPath, Verb...}PowerShell xSslSettings xwebadministration 3.2.0 {Bindings, Name, DependsOn, Ensure...}PowerShell xWebApplication xwebadministration 3.2.0 {Name, PhysicalPath, WebAppPool, Website...}PowerShell xWebAppPool xwebadministration 3.2.0 {Name, autoShutdownExe, autoShutdownParams, aut...PowerShell xWebAppPoolDefaults xwebadministration 3.2.0 {IsSingleInstance, DependsOn, IdentityType, Man...PowerShell xWebConfigKeyValue xwebadministration 3.2.0 {ConfigSection, Key, WebsitePath, DependsOn...}PowerShell xWebConfigProperty xwebadministration 3.2.0 {Filter, PropertyName, WebsitePath, DependsOn...}PowerShell xWebConfigPropertyColl... xwebadministration 3.2.0 {CollectionName, Filter, ItemKeyName, ItemKeyVa...PowerShell xWebSite xwebadministration 3.2.0 {Name, ApplicationPool, ApplicationType, Authen...PowerShell xWebSiteDefaults xwebadministration 3.2.0 {IsSingleInstance, AllowSubDirConfig, DefaultAp...PowerShell xWebVirtualDirectory xwebadministration 3.2.0 {Name, PhysicalPath, WebApplication, Website...}Get a single DSC resource detailsWith Get-DscResource cmdlet and the -Name and -Syntax arguments:Get-DscResource -Name xWebSite -SyntaxOutput:xWebSite [String] #ResourceName{ Name = [string] [ApplicationPool = [string]] [ApplicationType = [string]] [AuthenticationInfo = [MSFT_xWebAuthenticationInformation]] [BindingInfo = [MSFT_xWebBindingInformation[]]] [DefaultPage = [string[]]] [DependsOn = [string[]]] [EnabledProtocols = [string]] [Ensure = [string]{ Absent | Present }] [LogCustomFields = [MSFT_xLogCustomFieldInformation[]]] [LogFlags = [string[]]{ BytesRecv | BytesSent | ClientIP | ComputerName | Cookie | Date | Host | HttpStatus | HttpSubStatus | Method | ProtocolVersion | Referer | ServerIP | ServerPort | SiteName | Time | TimeTaken | UriQuery | UriStem | UserAgent | UserName | Win32Status }] [LogFormat = [string]{ IIS | NCSA | W3C }] [LoglocalTimeRollover = [bool]] [LogPath = [string]] [LogPeriod = [string]{ Daily | Hourly | MaxSize | Monthly | Weekly }] [LogTargetW3C = [string]{ ETW | File | File,ETW }] [LogTruncateSize = [string]] [PhysicalPath = [string]] [PreloadEnabled = [bool]] [PsDscRunAsCredential = [PSCredential]] [ServerAutoStart = [bool]] [ServiceAutoStartEnabled = [bool]] [ServiceAutoStartProvider = [string]] [SiteId = [UInt32]] [State = [string]{ Started | Stopped }]}Test a DSC configurationTest configurations specified in a folder with the Test-DscConfiguration cmdlet and the -Path argument:Test-DscConfiguration -Path myPathOutput:PSComputerName ResourcesInDesiredState ResourcesNotInDesiredState InDesiredState -------------- ----------------------- -------------------------- -------------- localhost {[WindowsFeature]IIS, [Wind... {[WindowsFeature]AspNet45, ... False Or:InDesiredState : FalseResourcesInDesiredState : {[WindowsFeature]IIS, [WindowsFeature]WebServerManagementConsole}ResourcesNotInDesiredState : {[WindowsFeature]AspNet45, [xWebSite]DefaultSite}ReturnValue : 0PSComputerName : localhostList featuresWith Get-WindowsFeature:Get-WindowsFeatureOutput:Display Name Name Install State------------ ---- -------------[ ] Active Directory Certificate Services AD-Certificate Available [ ] Certification Authority ADCS-Cert-Authority Available [ ] Certificate Enrollment Policy Web Service ADCS-Enroll-Web-Pol Available [ ] Certificate Enrollment Web Service ADCS-Enroll-Web-Svc Available [ ] Certification Authority Web Enrollment ADCS-Web-Enrollment Available [ ] Network Device Enrollment Service ADCS-Device-Enrollment Available [ ] Online Responder ADCS-Online-Cert Available[ ] Active Directory Domain Services AD-Domain-Services Available[ ] Active Directory Federation Services ADFS-Federation Available[ ] Active Directory Lightweight Directory Services ADLDS Available[ ] Active Directory Rights Management Services ADRMS Available [ ] Active Directory Rights Management Server ADRMS-Server Available [ ] Identity Federation Support ADRMS-Identity Available[ ] Device Health Attestation DeviceHealthAttestat... Available[ ] DHCP Server DHCP Available[ ] DNS Server DNS Available[ ] Fax Server Fax Available[X] File and Storage Services FileAndStorage-Services Installed [ ] File and iSCSI Services File-Services Available [ ] File Server FS-FileServer Available...Can also be rendered with a gridview thanks to Out-GridView:Get-WindowsFeature | Out-GridViewInstall a featureWith WindowsFeature:Examples:$titleIISRole = 'IIS role'$titleWindowsFeature = '[WindowsFeature]'$windowsFeatureIIS = \"$titleWindowsFeature$titleIISRole\"$statePresent = 'Present'# ...# Install the IIS roleWindowsFeature $titleIISRole { Ensure = $statePresent Name = 'Web-Server'}# Install the ASP .NET 4.7 role (yes the role's name ends with 45...)WindowsFeature \"ASP .NET 4.7 role\" { Ensure = $statePresent Name = 'Web-Asp-Net45' # It adds '[WindowsFeature]' as a prefix before the given title (same for each component) DependsOn = $windowsFeatureIIS}Create a web siteWith xWebsite:Example:$defaultWebSiteName = 'Default Web Site'$defaultWebSitePath = 'C:\\inetpub\\wwwroot'$statePresent = 'Present'$stateStarted = 'Started'$titleWindowsFeature = '[WindowsFeature]'$windowsFeatureIIS = \"$titleWindowsFeature$titleIISRole\"# ...# Default Web Site settingsxWebsite $defaultWebSiteName { Ensure = $statePresent Name = $defaultWebSiteName State = $stateStarted PhysicalPath = $defaultWebSitePath BindingInfo = @( MSFT_xWebBindingInformation { Protocol = \"http\" Port = 80 HostName = 'a.binding.myHost.com' }, MSFT_xWebBindingInformation { Protocol = \"https\" Port = 443 HostName = 'another.binding.myHost.com' CertificateThumbprint = 'aCertificateThumbrprint' } ) DependsOn = $windowsFeatureIIS}Create a virtual directoryWith xWebVirtualDirectory:Example:$defaultWebSiteName = 'Default Web Site'$titleXWebsite = '[xWebsite]'$xWebSiteDefaultWebSite = \"$titleXWebsite$defaultWebSiteName\"$statePresent = 'Present'$myDirectory = 'myDirectory'$mainVirtualDirectoryPath = Join-Path 'E:\\IIS\\Websites' -ChildPath $myDirectory# ...xWebVirtualDirectory $myDirectory { Name = $myDirectory PhysicalPath = $mainVirtualDirectoryPath WebApplication = '' Website = $defaultWebSiteName Ensure = $statePresent DependsOn = $xWebSiteDefaultWebSite}Create an application poolWith xWebAppPool:Example:$defaultWebSiteName = 'Default Web Site'$defaultWebSitePath = 'C:\\inetpub\\wwwroot'$statePresent = 'Present'$stateStarted = 'Started'$titleWindowsFeature = '[WindowsFeature]'$windowsFeatureIIS = \"$titleWindowsFeature$titleIISRole\"$applicationPoolName = 'My_Application_Pool'$poolGroupUser = \"IIS APPPOOL\\$applicationPoolName\"$applicationPoolIdentity = 'ApplicationPoolIdentity'# ...# Create a new application pool for the applicationxWebAppPool $applicationPoolName { Name = $applicationPoolName Ensure = $statePresent DependsOn = $windowsFeatureIIS # https://docs.microsoft.com/en-us/iis/configuration/system.applicationhost/applicationpools/applicationpooldefaults/ # This autoStart value can possibly not appear in the final file because its default value is true autoStart = $true # This managedRuntimeVersion value can possibly not appear in the final file if the same value is defined in the applicationPoolDefaults block (here v4.0) managedRuntimeVersion = $version4_0 startMode = $alwaysRunning # This identityType value can possibly not appear in the final file if the same value is defined in the applicationPoolDefaults block (here ApplicationPoolIdentity) identityType = $applicationPoolIdentity loadUserProfile = $true idleTimeout = \"00:00:00\" maxProcesses = 2 # https://docs.microsoft.com/en-us/iis/configuration/system.applicationhost/applicationpools/add/recycling/ # This disallowOverlappingRotation value can possibly not appear in the final file because its default value is false disallowOverlappingRotation = $false disallowRotationOnConfigChange = $true logEventOnRecycle = \"$memory, $configChange, $privateMemory\" restartRequestsLimit = 2000 restartTimeLimit = \"02:00:00\" rapidFailProtectionInterval = \"00:01:00\" rapidFailProtectionMaxCrashes = 20 # https://docs.microsoft.com/en-us/iis/configuration/system.applicationhost/applicationpools/add/recycling/periodicrestart/schedule/ # No restart schedule}Create a web applicationWith xWebApplication:Example:$defaultWebSiteName = 'Default Web Site'$defaultWebSitePath = 'C:\\inetpub\\wwwroot'$statePresent = 'Present'$stateStarted = 'Started'$titleWindowsFeature = '[WindowsFeature]'$windowsFeatureIIS = \"$titleWindowsFeature$titleIISRole\"$webAppPath = '...'$myDirectory = 'myDirectory'$applicationPoolName = 'My_Application_Pool'# \"DependsOn\" does not accept dependances named with slashes$iisRelativeNoVersionPath = \"$myDirectory/MyService\"$titleIisRelativeNoVersionPath = $iisRelativeNoVersionPath.Replace(\"/\", \"_\")$titleIisRelativeVersionPath = $iisRelativeVersionPath.Replace(\"/\", \"_\")# ...# Default Web Site settingsxWebApplication $titleIisRelativeVersionPath { Name = $iisRelativeVersionPath PhysicalPath = $webAppPath Website = $defaultWebSiteName WebAppPool = $applicationPoolName Ensure = $statePresent # To use SSL # SslFlags = $ssl SslFlags = '' ServiceAutoStartEnabled = $true ApplicationType = $applicationType ServiceAutoStartProvider = $serviceAutoStartProvider DependsOn = $xWebVirtualDirectoryRelativeNoVersionPath, $xWebAppPoolApplicationPoolName}Change hosts fileWith the NetworkingDsc module and HostsFile:Example:Import-DscResource -Module NetworkingDsc# ...HostsFile \"Modifying the hosts\" { HostName = \"myNewHost.myHost.com\" IPAddress = \"127.0.0.1\" Ensure = \"Present\"}" }, { "title": "IAM", "url": "/posts/misc-iam/", "categories": "IAM, Misc", "tags": "iam, misc", "date": "2022-06-23 09:00:00 +0200", "snippet": "IAM vs. IGAHow Do IGA and IAM Differ From Each Other?While they may sound very similar, Gartner takes care to distinguish between the function, extent, and purpose of IGA and IAM. Specifically, it notes, “IGA differs from IAM in that it allows organizations to not only define and enforce IAM policy, but also connect IAM functions to meet audit and compliance requirements.”. This means Identity Governance and Administration has the distinct purpose to ensure IAM policies are connected and enforced." }, { "title": "Acronyms", "url": "/posts/misc-acronyms/", "categories": "Acronyms, Misc", "tags": "acronyms, misc", "date": "2022-06-23 09:00:00 +0200", "snippet": "Acronyms AWS(fr): Amazon Web Services. It is a subsidiary of Amazon that provides on-demand cloud computing platforms and APIs. CAB: Change Advisory Board. It delivers support to a change-management team by advising on requested changes, assisting in the assessment and prioritization of changes. This body is generally made up of IT and Business representatives that include: a change manager, user managers and groups, technical experts and, possible third parties and customers. CTO: Chief Technology Officer. His occupation is focused on the scientific and technological issues within an organization. He will make decisions for the overarching technology infrastructure that closely align with the organization’s goals. BATX: Baidu Alibaba Tencent Xiaomi (chinese GAFAM). EC2(fr): Amazon Elastic Cloud Compute Microsoft. It’s a service (part of AWS) that allows users to rent virtual computers on which to run their own computer applications. FTE(fr): Full Time Equivalent (a.k.a. Wholeull Time Equivalent). It is a unit that indicates the workload of an employed person (or student) in a way that makes workloads or class loads comparable across various contexts. An FTE of 1.0 is equivalent to a full-time worker, while an FTE of 0.5 signals half of a full work. GAFAM: Google Apple Facebook Amazon Microsoft. IAM: Identity and Access Management. The discipline that enables the right individuals to access the right resources at the right times for the right reasons. Ie. with okta. IGA: Identity Governance and Administration. It automates the creation, management, and certification of user accounts, roles, and access rights for individual users in an organization. It’s the policy-based centralized orchestration of user identity management and access control, and it helps support enterprise IT security and regulatory compliance. Ie. with SailPoint. ITIL: Information Technology Infrastructure Library is a set of detailed practices for IT activities. KPI: Key Performance Indicator. It evaluates the success of an organization or of a particular activity (such as projects, programs, products and other initiatives) in which it engages. KPIs provides a focus for strategic and operational improvement, create an analytical basis for decision making and help focus attention on what matters most. LBO(fr): Leverage Buy-Out. It is one company’s acquisition of another company using a significant amount of borrowed money (leverage) to meet the cost of acquisition. MVP: Minimum Viable Product. A minimum viable product has just enough core features to effectively deploy the product, and no more. MTU(fr): Maximum Transmission Unit. Largest size of a network packet (protocol data unit - PDU) that can be communicated in a single network layer transaction (without being fragmented). OIDC(fr): Open ID Connect. It is an authentication layer on top of the OAuth 2.0 authorization framework.[82] It allows computing clients to verify the identity of an end user based on the authentication performed by an authorization server, as well as to obtain the basic profile information about the end user in an interoperable and REST-like manner. In technical terms, OpenID Connect specifies a RESTful HTTP API, using JSON as a data format. PAM: Privileged Access Management. Management of elevated access. RFP: Request For Proposal. A document that solicits proposal, often made through a bidding process, by an agency or company interested in procurement of a commodity, service, or valuable asset, to potential suppliers to submit business proposals (FR = appel d’offres). RTO(fr): Recovery Time Objective. Targeted duration of time and a service level within which a business process must be restored after a disaster (or disruption) in order to avoid unacceptable consequences associated with a break in business continuity. SAML(fr): Security Assertion Markup Language. It is an open standard for exchanging authentication and authorization data between parties, in particular, between an identity provider and a service provider. SAML is an XML-based markup language for security assertions (statements that service providers use to make access-control decisions). SLA: Service Level Agreement. Agreement made with clients. SLI: Service Level Indicator. Real numbers of the performance SLO: Service Level Objective. Objectives that must be met in order to reach the SLA. SOC: Security Operations Center. Facility where enterprise information systems (web sites, applications, databases, data centers and servers, networks, desktops and other endpoints) are monitored, assessed, and defended. SOD: Separation (or Segregation) Of Duty. It is the concept of having more than one person required to complete a task. It is an administrative control used by organisations to prevent fraud, sabotage, theft, misuse of information, and other security compromises. It’s like separation of powers in politics. UAT: User Acceptance Testing. Kind of beta testing, differs from technical and functional validation. VPC: Virtual Private Cloud. Pool of shared resources allocated within a public cloud environment, providing a certain level of isolation between the different organizations (denoted as users hereafter) using the resources. Kind of private cloud in a public one.MiscOAuth vs. OpenID vs. SAML" }, { "title": "AWS CLI", "url": "/posts/dev-misc-aws-cli/", "categories": "Development, AWS, CLI", "tags": "development, aws, cli", "date": "2022-06-23 09:00:00 +0200", "snippet": "AWS CLIFirst settingsAWS CLI referenceInstallation on Windows with myTenant tenant: Get the MSI Optional, desactivate the proxy for the S3 host:setx /m NO_PROXY bucket.s3storage.myTenant.fr Perform the first configuration steps with the aws configure command:aws configureIt will ask for:AWS Acces Key ID =AWS Secret Access Key =Default region name =Default output format = Then we can test the connection ie. listing the repository myRepo on the myTenant tenant content with the s3 command and the ls argument:aws --endpoint-url https://bucket.s3storage.myTenant.fr s3 ls s3://myRepo/ If there is a certificate problem, just put the appropriate .pem file in a directory, ie. C:\\Certificates and launch the following command:setx /m AWS_CA_BUNDLE \"C:\\Certificates\\myCertificate.pem\"Commands referenceCommands referenceS3Use the s3 command (S3 commands reference).List a repoWith the ls argument (ls reference):aws --endpoint-url https://bucket.s3storage.myTenant.fr s3 ls s3://myRepo/Copy a fileWith the cp argument (cp reference):aws --endpoint-url https://bucket.s3storage.myTenant.fr s3 cp source destinationIt’s the same command to get a file from the repo, ie.:aws --endpoint-url https://bucket.s3storage.myTenant.fr s3 cp s3://myRepo/myFile C:\\destinationFolderAnd for putting a file on the repo:aws --endpoint-url https://bucket.s3storage.myTenant.fr s3 cp C:\\sourceFolder\\myFile s3://myRepo/myFileDelete a file on the repoWith the rm argument (rm reference):aws --endpoint-url https://bucket.s3storage.myTenant.fr s3 rm s3://myRepo/myFile" }, { "title": "Postman", "url": "/posts/dev-misc-postman/", "categories": "Development, Postman", "tags": "development, postman", "date": "2022-06-23 09:00:00 +0200", "snippet": "Retrieve a collection variablesWith the pm object and the collectionVariables property:pm.collectionVariables.get(\"myVariableName\");Log somethingWith the pm object and the collectionVariables property:console.log(\"My console log message\");Perform a loop requestContextExample with: a query on the URI http://myUri that returns paged results and a link to the next page in its response payload (example with 100 results) an after parameter that enables to skip results, like: http://myUri?after=100So: first query is http://myUri, in its response payload the next link is http://myUri?after=100 second query is http://myUri?after=100, in its response payload the next link is http://myUri?after=200 it continues until there is no more result and so no more next link in the response payloadHow to? We have a collection variable called queryKeyAfter which value is after We will dynamically set a variable called after that will contain the results to skip. It’s this parameter that will enable to launch automatically a new query or not In the collection variables, we also have a variable named ie. count and set it to 0 before running the loop (only used as a queries performed counter) The query with pre-request and tests scripts will automatically loop In the query:Pre-request script:// We first check if the after parameter already existlet after = pm.collectionVariables.get(pm.collectionVariables.get(\"queryKeyAfter\"));// If so, we use its value and add it to the requestif (after &amp;&amp; after.length &gt; 0) { //console.log(\"Pre-request Script - After parameter retrieved from collection variables: \" + after); pm.request.url.query.add(pm.collectionVariables.get(\"queryKeyAfter\")); pm.request.url.query.idx(1).value = after;}else { // Display purposes only console.log(\"{\");}// Counterlet count = pm.collectionVariables.get(\"count\");if(!count || count.length == 0) { pm.collectionVariables.set(\"count\", 0);}Tests script:// Regexes for linksconst regexNextLink = /^(?:\\&lt;(.*)\\&gt;; rel=\\\"next\")$/gm;const regexAfter = /^.*\\?(?:.*&amp;)?after=(.*)(?:&amp;.*)$/gm;// Keysconst headerKeyLink = \"link\";const queryName = \"List Users LOOP\";// gets all given header key valuesfunction getAll(key) { let result = []; key = key.toLowerCase(); pm.response.headers.each((header) =&gt; { if (String(header.key).toLowerCase() === key) { result.push(header.valueOf()); } }); return result;}function main() { // Display purposes console.log(\"\\\"req_\" + pm.collectionVariables.get(\"count\") + \"\\\"\"); console.log(pm.response.json()); // Get the response content let allLinks = getAll(headerKeyLink); let nextLink = \"\"; allLinks.each((currentNextLink) =&gt; { let currentMatchNextLink; while ((currentMatchNextLink = regexNextLink.exec(currentNextLink)) !== null) { // This is necessary to avoid infinite loops with zero-width matches if (currentMatchNextLink.index === regexNextLink.lastIndex) { regexNextLink.lastIndex++; } nextLink = currentMatchNextLink[1]; let currentMatchAfter; while ((currentMatchAfter = regexAfter.exec(nextLink)) !== null) { // This is necessary to avoid infinite loops with zero-width matches if (currentMatchAfter.index === regexAfter.lastIndex) { regexAfter.lastIndex++; } //console.log(\"Tests Script - Retrieved next after is \" + currentMatchAfter[1]); // Next linkk is found, we set the next \"after\" parameter value and update the counter pm.collectionVariables.set(pm.collectionVariables.get(\"queryKeyAfter\"), currentMatchAfter[1]); pm.collectionVariables.set(\"count\", pm.collectionVariables.get(\"count\") + 1); } } }); // There is still a next link if (nextLink !== \"\") { console.log(\",\"); // Next query is launched postman.setNextRequest(queryName); } else { // The end: we remove the collection variable pm.collectionVariables.unset(pm.collectionVariables.get(\"queryKeyAfter\")); // Display purposes only console.log(\"}\"); }}main();" }, { "title": "Telegraf", "url": "/posts/linux-telegraf/", "categories": "Telegraf", "tags": "Telegraf, tips", "date": "2022-06-16 09:10:00 +0200", "snippet": "TelegrafGlobal configurationBy default, file /etc/telegraf/telegraf.conf:# Custom global tags (will be sent with each metric)[global_tags] env = \"myEnv\" environment = \"DEVELOPPEMENT\" etat = \"Installed\"[agent] # Default data collection interval for all inputs interval = \"10s\" # Rounds collection interval to interval. For example, if interval is set to 10s then always collect on :00, :10, :20, etc. round_interval = true # Telegraf will send metrics to output in batch of at most metric_batch_size metrics - Maximum number of metrics to send at once metric_batch_size = 10000 # Telegraf will cache metric_buffer_limit metrics for each output, and will flush this buffer on a successful write. This should be a multiple of metric_batch_size and could not be less than 2 times metric_batch_size - Maximum number of unsent metrics to buffer metric_buffer_limit = 10000 # Collection jitter is used to jitter the collection by a random amount. Each plugin will sleep for a random time within jitter before collecting. This can be used to avoid many plugins querying things like sysfs at the same time, which can have a measurable effect on the system collection_jitter = \"0s\" # Default data flushing interval for all outputs. You should not set this below interval. Maximum flush_interval will be flush_interval + flush_jitter flush_interval = \"60m\" # Jitter the flush interval by a random amount. This is primarily to avoid large write spikes for users running a large number of Telegraf instances. For example, a flush_jitter of 5s and flush_interval of 10s means flushes will happen every 10-15s flush_jitter = \"60m\" # Collected metrics are rounded to the precision specified as an interval (integer + unit, ex: 1ns, 1us, 1ms, and 1s . Precision will NOT be used for service inputs, such as logparser and statsd precision = \"\" # Run Telegraf in debug mode debug = false # Run Telegraf in quiet mode (error messages only) quiet = true # Specify the log file name. The empty string means to log to stderr logfile = \"/dev/null\" # If true, do no set the host tag in the Telegraf agent omit_hostname = falseConfiguration files directoryBy default, directory /etc/telegraf/telegraf.d: telegraf reads each .conf file and concatenates everything to make a big unique configuration file for him.Test configurationWith the telegraf -test command: telegraf -test -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --input-filter=execIt’s possible to filter on a given input type, ie. exec: telegraf -test -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --input-filter=execOr an output type, ie. dynatrace: telegraf -test -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --output-filter=dynatraceFilters can be combined (it performs an or between different filters): telegraf -test -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d --input-filter=exec --output-filter=dynatraceSource" }, { "title": "System", "url": "/posts/windows-system/", "categories": "System", "tags": "system, tips", "date": "2022-06-08 14:30:00 +0200", "snippet": "System commandsConsoles generic one: mmc users and groups: lusrmgr.mscCreate aliases to a database: with cliconfg: Alias tab select TCP/IP type both alias in Server alias and instance\\database in Server name " }, { "title": "PowerShell system", "url": "/posts/windows-powershell-system/", "categories": "System, PowerShell", "tags": "system, powershell, tips", "date": "2022-05-31 15:00:00 +0200", "snippet": "System commandsPowerShell versionWith $PSVersionTable.PSVersion (see $PSVersionTable):$PSVersionTable.PSVersionOutput:Major Minor Build Revision----- ----- ----- --------5 1 19041 1682Users and groupsCreate a local groupWith the New-LocalGroup cmdlet:New-LocalGroup -Name \"MySecurityGroup\"Check if a local group existWith the Get-LocalGroup cmdlet:$myGroup = \"MySecurityGroup\"try { Get-LocalGroup -Name \"$myGroup\" -ErrorAction Stop Write-Host \"myGroup $myGroup found!\"}catch { Write-Host \"myGroup $myGroup does not exist\"}Check if a local group contains a memberWith the Get-LocalGroupMember cmdlet:try { Get-LocalGroupMember -Group \"$myGroup\" -Member $myUser -ErrorAction Stop Write-Host \"Group $myGroup already contains user $myUser!\"}catch { Write-Host \"Group $myGroup does not contain user $myUser\"}Add a user to a local groupWith the Add-LocalGroupMember cmdlet:Add-LocalGroupMember -Group \"MySecurityGroup\" -Member \"MyMember\"Telnet alternativeWith Test-NetConnection cmdlet:Test-NetConnection -computername myHost.com -port 1234Output:ComputerName : myHost.comRemoteAddress : 111.222.333.444RemotePort : 1234InterfaceAlias : Prod_1SourceAddress : 111.333.222.444TcpTestSucceeded : TrueFor a SQL Server connection, test the 58227 port.wget alternativeWith Invoke-WebRequest cmdlet:Invoke-WebRequest https://myHost.com/foo/barOutput:StatusCode : 200StatusDescription : OKContent : {\"someJSONKey\":\"someJSONValue\"}RawContent : HTTP/1.1 200 OK x-xss-protection: 0 content-security-policy: frame-ancestors 'self' vary: Origin x-content...Forms : {}Headers : {[x-xss-protection, 0], [content-security-policy, frame-ancestors 'self'], [expect-ct, max-age=0], [vary, Origin]...}Images : {}InputFields : {}Links : {}ParsedHtml : System.__ComObjectRawContentLength : 1940IISCreate a shared configurationWith Enable-IISSharedConfig and Export-IISConfiguration:# Configure shared configuration (even if alone, simpler to edit)*$IISSharedConfigPath = \"sharedPath\"$KeyEncryptionPasswordPlainText = \"password\"New-Item -Path $IISSharedConfigPath -ItemType Directory -Force$KeyEncryptionPassword = ConvertTo-SecureString -AsPlainText -String $KeyEncryptionPasswordPlainText -ForceExport-IISConfiguration -PhysicalPath $IISSharedConfigPath -KeyEncryptionPassword $KeyEncryptionPasswordEnable-IISSharedConfig -PhysicalPath $IISSharedConfigPath -KeyEncryptionPassword $KeyEncryptionPasswordDisable a shared configurationWith Disable-IISSharedConfig:Disable-IISSharedConfig" }, { "title": "Users and groups", "url": "/posts/linux-users-and-groups/", "categories": "System, Linux", "tags": "system, linux, shell, tips, users, groups", "date": "2022-05-13 09:00:00 +0200", "snippet": "GroupsCreate a groupCreate a group with a given GID (thanks to -g argument) and a given name:groupadd -g &lt;gid&gt; &lt;groupName&gt;Example:groupadd -g 1000 myGroupDelete a groupWith the groupdel command:groupdel &lt;groupName&gt;Example:groupdel myGroupList existing groupscat /etc/groupExample output:input:x:105:kvm:x:106:render:x:107:crontab:x:108:netdev:x:109:myGroup:x:1000:ssh:x:110:List current user groupsgroupsExample output:myGroup secondaryGroupUsersCreate a userCreate a user with: -d: its home directory -u: its UID -g: its GID (warning: -g belongs to the user’s primary group)Followed by its name:useradd -d &lt;homeDirectory&gt; -u &lt;uid&gt; -g &lt;gid&gt; &lt;userName&gt;Example:useradd -d /home/myUser -u 1000 -g 1000 myUserDelete a userWith the userdel command:userdel &lt;userName&gt;Example:userdel myUserNote: when a user is deleted, its primary group is also deleted, unless that group also contains other users.List existing userscat /etc/passwdExample output:root:x:0:0:root:/root:/bin/bashdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinUser’s groupsChange user’s primary group with -g:usermod -g myNewGroup myUserAdd user to secondary groups with combination of -a and -G:usermod -a -G secondaryGroup,otherSecondaryGroup myUserMixedList a user’s groups and ids:idExample output:uid=1000(myUser) gid=1000(rhds) groups=1000(myGroup),2000(secondaryGroup)" }, { "title": "Cut", "url": "/posts/linux-cut/", "categories": "System, Linux", "tags": "system, linux, shell, tips, cut", "date": "2022-05-11 09:00:00 +0200", "snippet": "CutIt removes sections from each line of files, of from standard input if no file given. Defaule delimiter is the tabulation.Example for displaying the first element (index starts at 1):echo \"ONE TWO THREE FOUR\" | cut -f1Output:ONETo specify a delimiter:echo \"ONE;TWO;THREE;FOUR\" | cut -d ';' -f 2Output:TWOTo get several parts:echo \"ONE;TWO;THREE;FOUR\" | cut -d ';' -f 2-3Output:TWO;THREE" }, { "title": "Dnf", "url": "/posts/linux-dnf/", "categories": "System, Linux", "tags": "system, linux, shell, tips, dnf", "date": "2022-04-15 09:00:00 +0200", "snippet": "List reposdnf repolistOnly the enabled ones:dnf repolist enabledOnly the disabled ones:dnf repolist disabledRepos descriptionsRepos files descriptions are located under /etc/yum.repos.d/, ie. test.repo:# Comment[test-repo-one]name=test-repo-onebaseurl=...repo_gpgcheck=1enabled=1gpgkey=...gpgcheck=1sslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300pkg_gpgcheck=1autorefresh=1type=rpm-md[test-repo-two]name=csi-test-repo-twobaseurl=...repo_gpgcheck=1enabled=1gpgkey=...gpgcheck=1sslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300pkg_gpgcheck=1autorefresh=1type=rpm-mdTo enable its content:dnf -q makecache -y --enablerepo='test-repo*'" }, { "title": "HashiCorp Vault", "url": "/posts/misc-hashicorp-vault/", "categories": "Markdown, Misc, HashiCorp, Vault", "tags": "markdown, misc, hashicorp, vault", "date": "2022-04-14 09:00:00 +0200", "snippet": "Request secret with cURLHere with a cURL specfiic version (that can read from Windows certificates store):curl -x \"&lt;PROXY&gt;\" --request POST -k --cert CERT_THUMBPRINT --data \"{\\\"name\\\": \\\"VAULT_ROLE\\\"}\" VAULT_URL -i -verbose --trace-ascii .\\trace-ascii.txtWith: PROXY: target proxy CERT_THUMBPRINT: full certificate path and thumbprint, ie. LocalMachine\\My\\12345612345764CE4A71D440E20FAC5E5123456 VAULT_ROLE: the role granted to use Vault VAULT_URL: Vault login endpoint, ie. https://myVault.com/v1/auth/cert/login" }, { "title": "Apache tips", "url": "/posts/linux-apache-tips/", "categories": "System, Linux, Apache", "tags": "system, linux, shell, tips, apache", "date": "2022-03-30 09:00:00 +0200", "snippet": "AliasesHere consider http://myServer as ServerRoot.Simple aliasesAlias /alias sub/pathHere http://myServer/alias and http://myServer/sub/path are now the same.Script aliasesScriptAlias /cgi-bin https/cgi-binHere http://myServer/cgi-bin and http://myServer/https/cgi-bin are now the same.Remark: everything under the script alias will be executed, so we can’t put CSS or JS files inside.Location aliases&lt;Location \"/ping\"&gt; Alias \"http/ping.txt\"&lt;/Location&gt;Here http://myServer/ping and http://myServer/http/ping.txt are now the same. Useful for a healthcheck for example.Apache server that listens to several portsSimply one ServerRoot, several Listen port, ie.:# We define the server root pathServerRoot \"/myPath\"# We define the ports the Apache instance listens toListen 8080Listen 8443Then several virtual hosts:&lt;VirtualHost *:8080&gt; DocumentRoot http ErrorLog logs/error_log_http LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b\" common CustomLog logs/access_log_http common ServerName myServer Options -Indexes&lt;/VirtualHost&gt;&lt;VirtualHost *:8443&gt; DocumentRoot https ErrorLog logs/error_log_https LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b\" common CustomLog logs/access_log_https common ServerName myServer Options -Indexes&lt;/VirtualHost&gt;Remark: aliases, script aliases, etc. must be set at the virtual host level, or they will be global (that means ok for every virtual host).More complete example:# Unique server rootServerRoot \"/myBasePath/apache//myCustomPath\"# We define the ports the Apache instance listens toListen 8080Listen 8443# ModulesLoadModule unixd_module /etc/httpd/modules/mod_unixd.soLoadModule mpm_event_module /etc/httpd/modules/mod_mpm_event.soLoadModule autoindex_module /etc/httpd/modules/mod_autoindex.soLoadModule dir_module /etc/httpd/modules/mod_dir.soLoadModule alias_module /etc/httpd/modules/mod_alias.soLoadModule cgi_module /etc/httpd/modules/mod_cgi.soLoadModule auth_basic_module /etc/httpd/modules/mod_auth_basic.soLoadModule authn_file_module /etc/httpd/modules/mod_authn_file.soLoadModule authn_core_module /etc/httpd/modules/mod_authn_core.soLoadModule authz_core_module /etc/httpd/modules/mod_authz_core.soLoadModule authz_host_module /etc/httpd/modules/mod_authz_host.soLoadModule authz_user_module /etc/httpd/modules/mod_authz_user.soLoadModule ldap_module /etc/httpd/modules/mod_ldap.soLoadModule authnz_ldap_module /etc/httpd/modules/mod_authnz_ldap.soLoadModule mime_module /etc/httpd/modules/mod_mime.soLoadModule headers_module /etc/httpd/modules/mod_headers.soLoadModule log_config_module /etc/httpd/modules/mod_log_config.soLoadModule systemd_module /etc/httpd/modules/mod_systemd.so# User &amp; group used to start this instance of httpd serviceUser myUserGroup myGroup# Virtual host definitions# First host accessible through HTTP&lt;VirtualHost *:8080&gt; DocumentRoot http ErrorLog logs/error_log_http LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b\" common CustomLog logs/access_log_http common ServerName myServer Options -Indexes # URL aliases (the document root will be accessible via /subPath/foo) Alias /subPath/foo http/foo Alias /subPath http/foo&lt;/VirtualHost&gt;# Other host accessible through HTTPS&lt;VirtualHost *:8443&gt; DocumentRoot https ErrorLog logs/error_log_https LogFormat \"%h %l %u %t \\\"%r\\\" %&gt;s %b\" common CustomLog logs/access_log_https common ServerName myServer Options -Indexes # Warning: everything under ScriptAlias is interpreted as a script, so pictures etc. can't be in this kind of location # Script alias for CGI ScriptAlias /cgi-bin https/cgi-bin # Script alias for tools ScriptAlias /tools https/cgi-bin/tools&lt;/VirtualHost&gt;# Disable to download sub .htaccess files&lt;FilesMatch \"^\\.ht\"&gt; Require all denied&lt;/FilesMatch&gt;# Alias to a single file: ping endpoint for healthcheck&lt;Location \"/ping\"&gt; Alias \"http/ping.txt\"&lt;/Location&gt;# Tools directory with LDAP authentication and group appartenance check&lt;Directory /myBasePath/apache//myCustomPath/https/cgi-bin/tools&gt; AuthType Basic AuthName \"ARCA LDAP authentication\" AuthBasicProvider ldap AuthLDAPURL \"ldap://myLdapServer:389/ou=myOtherOu,o=myO???(&amp;(objectClass=person)(!(accountsuspended=1))(!(passwordexpirationtime=19700101000000Z)))\" NONE AuthLDAPBindDN \"uid=myUid,ou=myOu,ou=myOtherOu,o=myO\" AuthLDAPBindPassword \"myPassword\" Require ldap-group cn=use_apache_tools,cn=/myCustomPath,ou=Applications,ou=myRightsOu,o=myO AddType text/css .css AddType text/javascript .js&lt;/Directory&gt;# CGI directory: no direct access, only in subdirectories&lt;Directory /myBasePath/apache//myCustomPath/https/cgi-bin&gt; Require all denied&lt;/Directory&gt;" }, { "title": "Perl tips", "url": "/posts/perl-tips/", "categories": "Development, Perl", "tags": "development, perl, tips", "date": "2022-03-30 09:00:00 +0200", "snippet": "Get Perl versionperl -vCheck if a module is installedWith perl -e 'use &lt;MODULE&gt;;'. Example:perl -e 'use Time::HiRes;'Or with perl -M&lt;MODULE&gt; -e 1. Example:perl -MTime::HiRes -e 1If it exists, not output, otherwise:Can't locate Time/HiRes.pm in @INC (you may need to install the Time::HiRes module) (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5) at -e line 1.BEGIN failed--compilation aborted at -e line 1.Get date since epochWithout additional package on Perl older versions, depending on format, with the system date command, ie.:$date = `date +%s%N`;Otherwise with Time::HiRes::time (and perhaps POSIX::strftime for formatting - source):use Time::HiRes qw(time);use POSIX qw(strftime);my $t = time;my $date = strftime \"%Y%m%d %H:%M:%S\", localtime $t;$date .= sprintf \".%03d\", ($t-int($t)) * 1000; # without roundingprint $date, \"\\n\";" }, { "title": "JSON query", "url": "/posts/ansible-json-query/", "categories": "System, Linux, Ansible, YAML, JSON", "tags": "system, linux, ansible, yaml, tips, json, query", "date": "2022-03-04 09:00:00 +0100", "snippet": "WIPUseful links Parse JSON using Ansible json_query JMESPath Tutorial" }, { "title": "Git tags", "url": "/posts/git-tags/", "categories": "Development, Git, GitLab, GitHub", "tags": "development, git, gitlab, github", "date": "2022-03-02 15:15:00 +0100", "snippet": "Full documentationList tagsWith -l argument:git tag -lOutput example:v1.0.0v1.0.1List annotations with -n argument and the number of lines to display. -n implies -l:git tag -n1Output example:v1.0.0 First PROD versionv1.0.1 Second PROD versionCreate a complete taggit tag -a myTag -m 'My tag comment'Push this tag on remote hostgit push origin myTagDelete a remote taggit push --delete origin myTagDelete a local taggit tag -d myTagDelete/recreate a tag Tools like AWX sometimes do not like deleted/recreated tags while updating from source.# Settings$tag = \"v1.0.0\"$tagComment = \"My tag comment\"$branchDevelop = \"develop\"$branchMain = \"main\"# Going on \"develop\" branchgit checkout $branchDevelopgit pull# Deleting actual taggit push --delete origin $taggit tag -d $tag# Going on \"master/main\" branchgit checkout $branchMaingit pull# Creating a new taggit tag -a $tag -m \"$tagComment\"git push origin $taggit checkout $branchDevelop" }, { "title": "Apt", "url": "/posts/linux-apt/", "categories": "System, Linux", "tags": "system, linux, shell, tips, apt", "date": "2021-11-24 14:00:00 +0100", "snippet": "Search for a package with the list command, ie. apache2apt list apache2Output:Listing... Doneapache2/stable,stable 2.4.38-3+deb10u4 amd64Search for all package versions with the list command and the -a argument, ie. apache2apt list -a apache2Output:Listing... Doneapache2/buster-backports 2.4.46-4~bpo10+1 amd64apache2/stable,stable 2.4.38-3+deb10u4 amd64Search for a package pattern with the search command (not a wildcard), ie. with apache2apt search apache2Output:Sorting... DoneFull Text Search... Doneapache2/stable,stable 2.4.38-3+deb10u4 amd64 Apache HTTP Serverapache2-bin/stable,stable 2.4.38-3+deb10u4 amd64 Apache HTTP Server (modules and other binary files)apache2-data/stable,stable 2.4.38-3+deb10u4 all Apache HTTP Server (common files)apache2-dev/stable,stable 2.4.38-3+deb10u4 amd64 Apache HTTP Server (development headers)...Configure a proxy for aptGo to /etc/apt/apt.conf.d and add a custom file, ie. 99myCustomFile. Edit it with elevated rights:sudo vi 99myCustomFileAnd add this line:Acquire::http::Proxy \"http://&lt;USER_LOGIN&gt;:&lt;USER_PASSWORD&gt;@&lt;PROXY_URL&gt;:&lt;PROXY_PORT&gt;\";" }, { "title": "Yum", "url": "/posts/linux-yum/", "categories": "System, Linux", "tags": "system, linux, shell, tips, yum", "date": "2021-11-24 14:00:00 +0100", "snippet": "Search for a package, ie. httpdyum list httpdOutput:Last metadata expiration check: 0:52:22 ago on Wed 24 Nov 2021 01:23:02 PM CET.Available Packageshttpd.x86_64 2.4.37-39.module+el8.4.0+12865+a7065a39.1 rhel-8-for-x86_64-appstream-rpmsSearch for a package pattern, ie. httpd*yum list httpd*Output:Last metadata expiration check: 0:50:17 ago on Wed 24 Nov 2021 01:23:02 PM CET.Available Packageshttpd.x86_64 2.4.37-39.module+el8.4.0+12865+a7065a39.1 rhel-8-for-x86_64-appstream-rpmshttpd-devel.x86_64 2.4.37-39.module+el8.4.0+12865+a7065a39.1 rhel-8-for-x86_64-appstream-rpmshttpd-filesystem.noarch 2.4.37-39.module+el8.4.0+12865+a7065a39.1 rhel-8-for-x86_64-appstream-rpmshttpd-manual.noarch 2.4.37-39.module+el8.4.0+12865+a7065a39.1 rhel-8-for-x86_64-appstream-rpmshttpd-tools.x86_64 2.4.37-39.module+el8.4.0+12865+a7065a39.1 rhel-8-for-x86_64-appstream-rpmsMore than useful linksYum cheat sheet" }, { "title": "Bash tips", "url": "/posts/bash-tips/", "categories": "System, Linux, Bash, Shell", "tags": "system, linux, bash, shell, tips", "date": "2021-06-23 15:00:00 +0200", "snippet": "Change a symbolic link ownerThanks to the -h argument:chown -h mySymLinkLoop on a command outputUse a while loop on the results. The classic while syntax uses a subshell, so a Here String syntax is needed (documentation - see this SO post for details). Example, looking in LV containing the string FOO and for a folder that ends by bar:MY_VAR=\"\"VALUES=$(df --output=source,target|grep FOO|sed -r \"s/\\s+/;/g\"|cut -d';' -f2)while read -r df_output ; do if [[ $df_output =~ ^(.*)/bar$ ]]; then TARGET_BASE_DIR=\"${BASH_REMATCH[1]}\" MY_VAR=$(echo $TARGET_BASE_DIR | sed -r \"s/.*\\/([^\\/]*)$/\\1/\") fidone &lt;&lt;&lt; \"$VALUES\"" }, { "title": "Ansible add host", "url": "/posts/ansible-add-host/", "categories": "System, Linux, Ansible, YAML", "tags": "system, linux, ansible, yaml, tips, add, host", "date": "2021-06-18 10:00:00 +0200", "snippet": "Add an host at runtimeThe add_host module is useful to dynamically add an host to the current playbook execution. Classic usage would be: a task creates an host, ie. a VM the next task has to be performed on the newly created VMA less usual usage, ie. from an AWX side, would be to have a job templated linked with an empty inventory and a playbook where all the hosts will be dynamically added.Here a simple example that will use the following variables file to add hosts dynamically (this variables file could also be loaded dynamically depending on a variable set on the AWX side):---my_hosts: - ansible_hostname_short: 'host_1' ansible_hostname: 'host_1.myDomain.com' instances: - index: 1 port: \"11389\" secure_port: \"11636\" alias: \"D01\" - ansible_hostname_short: 'host_2' ansible_hostname: 's4855ars.myDomain.com'Here an example playbook called from AWX, where a awx_defined_group variable is defined:---- name: 'First part: we just dynamically add the hosts' # localhost must be kept here hosts: localhost connection: local gather_facts: no # Loading a host file at runtime vars_files: \"./vars/hosts_{{ awx_defined_group }}.yml\" tasks: # Adding all the hosts - name: Add hosts add_host: hostname: '{{ host_item.ansible_hostname_short }}' ansible_hostname_short: '{{ host_item.ansible_hostname_short }}' ansible_hostname: '{{ host_item.ansible_hostname }}' # Important in our example: a group must be set groupname: '{{ awx_defined_group }}' with_items: \"{{ my_hosts }}\" loop_control: loop_var: host_item# Here a new part with another \"tasks\" keyword where we also set a new value for the \"hosts\" keyword - name: 'Second part: using new hosts' # We only use the knewly added group hosts: '{{ awx_defined_group }}' tasks: # A simple ping to be sure that we can call our new groups - ansible.builtin.ping:Module’s documentation" }, { "title": "Ansible config", "url": "/posts/ansible-config/", "categories": "System, Linux, Ansible, YAML", "tags": "system, linux, ansible, yaml, tips", "date": "2021-05-31 10:00:00 +0200", "snippet": "See Ansible configurationTo see Ansible configuration, use the ansible-config utility, ie.:ansible-config listInfos that you can find:DEFAULT_MODULE_PATH: default: ~/.ansible/plugins/modules:/usr/share/ansible/plugins/modules description: Colon separated paths in which Ansible will search for Modules. env: - {name: ANSIBLE_LIBRARY} ini: - {key: library, section: defaults} name: Modules Path type: pathspecFull documentationChange parameters in Ansible configurationThe configuration files are: /etc/ansible/ansible.cfg: config file, used if present ~/.ansible.cfg: user config file, overrides the default config if presentA .cfg file can also be present at the playbook levelAdd a custom pathExample for modules: ie. edit the /etc/ansible/ansible.cfg file, at the beginning everything is commented:[defaults]# some basic default values...#inventory = /etc/ansible/hosts#library = /usr/share/my_modules/Just add a custom path (use a : to separate values):[defaults]# some basic default values...#inventory = /etc/ansible/hostslibrary = /usr/share/my_modules/:~user/ansible_custom/libraryIf we execute a playbook in verbose mode (-vvv), we can see:ansible-playbook -i hosts.yaml playbook.yml -vvvOutput:ansible-playbook 2.7.7 config file = /etc/ansible/ansible.cfg configured module search path = ['/usr/share/my_modules', '/home/user/ansible_custom/library']For filters, etc., it’s here:# set plugin path directories here, separate with colons#action_plugins = /usr/share/ansible/plugins/action#cache_plugins = /usr/share/ansible/plugins/cache#callback_plugins = /usr/share/ansible/plugins/callback#connection_plugins = /usr/share/ansible/plugins/connection#lookup_plugins = /usr/share/ansible/plugins/lookup#inventory_plugins = /usr/share/ansible/plugins/inventory#vars_plugins = /usr/share/ansible/plugins/varsfilter_plugins = /usr/share/ansible/plugins/filter:~user/ansible_custom/filter#test_plugins = /usr/share/ansible/plugins/test#terminal_plugins = /usr/share/ansible/plugins/terminal#strategy_plugins = /usr/share/ansible/plugins/strategy" }, { "title": "Cron", "url": "/posts/linux-cron/", "categories": "System, Linux", "tags": "system, linux, shell, tips, cron", "date": "2021-05-10 14:00:00 +0200", "snippet": "List crontabWith the -l argument:crontab -lEdit crontabWith the -e argument:crontab -eSpecify the user to interact with its crontabWith the -u argument:crontab -u myUserInstructionsRight now just check crontab guruDelete crontabWith the -r argument:crontab -rAllow/deny a user to use a crontab (on RHEL)Just add the user name in one of these files: /etc/cron.allow /etc/cron.denyBackup crontabcrontab -l &gt; myCrontabBackupUpdate crontab from fileIt replaces the current crontab with the one in the input filecrontab myCrontabUpdateFileExample: add a line in myUser user’s crontab from script# Backup actual crontabcrontab -l -u myUser &gt; crontab_myUser_backupNEW_LINE='the line to be added'echo \"${NEW_LINE}\" &gt;&gt; crontab_myUser_backupcrontab -u myUser crontab_myUser_backuprm -f crontab_myUser_backup" }, { "title": "Ansible lists and dictionaries", "url": "/posts/ansible-lists-and-dictionaries/", "categories": "System, Linux, Ansible, YAML, Lists, Dictionaries", "tags": "system, linux, ansible, yaml, tips, lists, dictionaries", "date": "2021-05-06 16:00:00 +0200", "snippet": "Add a key/value pair to an existing dictionaryAnother dictionary is needed, and the use of combine:- name: First dictionary ansible.builtin.set_fact: my_dictionary: property_1: \"Foo\" property_2: \"Bar\" - name: Temp dummy fact to add a new key value ansible.builtin.set_fact: dummy_dictionary: property_3: \"Baz\" - name: Adding a new fact to the current dirsrv instance one ansible.builtin.set_fact: my_dictionary: \"{{ my_dictionary | combine(dummy_dictionary) }}\"my_dictionary contains:{ \"my_dictionary\": { \"property_1\": \"Foo\", \"property_2\": \"Bar\", \"property_3\": \"Baz\" }}Convert a simple list into a dictionaryWith the input list:strings: - 'firstString' - 'secondString'To convert it into a dictionary, here with the list item as key and false as value:- ansible.builtin.set_fact: strings_with_state_into_dictionary: \"{{ strings_with_state_into_dictionary | default({}) | combine ({ string_item : false }) }}\" loop: \"{{ strings }}\" loop_control: loop_var: string_itemdefault({}) initializes strings_with_state_into_dictionary with an empty dictionary, combine fills the dictionary with the key : value syntax.Example of complex data manipulationHere we need to check for an input mounts list: if each mount exist if each mount is mounted on a separate deviceWith this given input list:input_mounts: - '/' - '/my_directory' - '/my_directory/my_user'Getting all the mounts:- name: Getting all existing mounts ansible.builtin.set_fact: existing_mounts: \"{{ ansible_mounts | map(attribute='mount') | list }}\" changed_when: falseFirst step, ansible_mounts (Ansible fact), will produce something like that:{ \"block_available\": 503381, \"block_size\": 4096, \"block_total\": 521728, \"block_used\": 18347, \"device\": \"/dev/mapper/vg00-lvroot\", \"fstype\": \"xfs\", \"inode_available\": 1047462, \"inode_total\": 1048576, \"inode_used\": 1114, \"mount\": \"/\", \"options\": \"rw,relatime,attr2,inode64,noquota\", \"size_available\": 2061848576, \"size_total\": 2136997888, \"uuid\": \"98760513-d53a-4801-8f37-7fb813ffdf24\"},{ \"block_available\": 629910, \"block_size\": 4096, \"block_total\": 1046016, \"block_used\": 416106, \"device\": \"/dev/mapper/vg00-lvusr\", \"fstype\": \"xfs\", \"inode_available\": 2054141, \"inode_total\": 2097152, \"inode_used\": 43011, \"mount\": \"/usr\", \"options\": \"rw,nodev,relatime,attr2,inode64,noquota\", \"size_available\": 2580111360, \"size_total\": 4284481536, \"uuid\": \"1345becf-f2ca-49db-a7dc-8103c65bde67\"}Second step, map(attribute='mount'), will “map” every object into a new one by selecting only the attribute mount. It would give something like that (not outputed with a debug task):{ \"mount\": \"/\"},{ \"mount\": \"/usr\"}Then the list will turn these objects into a unique list with the unique attribute (so mount) values:{ \"msg\": [ \"/\", \"/usr\" ]}Now we can check if every input mount is defined:- name: Checking if all the needed mounts exist ansible.builtin.assert: that: item in existing_mounts fail_msg: \"Mount {{ item }} does not exist\" with_items: \"{{ input_mounts }}\"To check if each mount is mounted on a separate device, we’ll need to group Ansible mounts by device, using {{ ansible_mounts | groupby('device') }}, in order to have a mounts list per device (there can be several mounts on the same device). With the previous sample, it would give:{ \"msg\": [ [ \"/dev/mapper/vg00-lvroot\", [ { \"mount\": \"/\", \"device\": \"/dev/mapper/vg00-lvroot\", \"fstype\": \"xfs\", \"options\": \"rw,relatime,attr2,inode64,noquota\", \"size_total\": 2136997888, \"size_available\": 2061864960, \"block_size\": 4096, \"block_total\": 521728, \"block_available\": 503385, \"block_used\": 18343, \"inode_total\": 1048576, \"inode_available\": 1047461, \"inode_used\": 1115, \"uuid\": \"98760513-d53a-4801-8f37-7fb813ffdf24\" } ] ], [ \"/dev/mapper/vg00-lvusr\", [ { \"mount\": \"/usr\", \"device\": \"/dev/mapper/vg00-lvusr\", \"fstype\": \"xfs\", \"options\": \"rw,nodev,relatime,attr2,inode64,noquota\", \"size_total\": 4284481536, \"size_available\": 2580959232, \"block_size\": 4096, \"block_total\": 1046016, \"block_available\": 630117, \"block_used\": 415899, \"inode_total\": 2097152, \"inode_available\": 2054141, \"inode_used\": 43011, \"uuid\": \"1345becf-f2ca-49db-a7dc-8103c65bde67\" } ] ] ]}The final test: we loop on the mounts list grouped by device on each item of this list, so one loop per device: we declare a variable temp_mounts that contains the list of the mounts of the current device we intersect this variable with the input mounts. If the intersection’s length is greater than one, it would mean that several input mounts are on the same device - name: Checking if the needed mounts are all mounted on separated devices ansible.builtin.assert: # temp_mounts belong to an unique device, so we intersect its list with the input one: if more than one match it means that there is more than one input mount on the same device that: temp_mounts | intersect(input_mounts) | length &lt;= 1 # In the loop, item.0 is the dictionary's current item's key fail_msg: \"Multiple mounts {{ temp_mounts }} on device {{ item.0 }}\" # We group the existing mounts by device, and build a list of mounts that belong to the given device (ie. { dev1: [mnt1, mnt2], dev2: [mnt3] }). We loop on it loop: \"{{ ansible_mounts | groupby('device') }}\" vars: # In the loop, item.1 is the dictionary's current item's value (so the mounts list): thus in each loop we retrieve the mounts that belong to the current device, ie. [mnt1, mnt2] for dev1 temp_mounts: \"{{ item.1 | map(attribute='mount') | list }}\"" }, { "title": "Ansible IO", "url": "/posts/ansible-io/", "categories": "System, Linux, Ansible, YAML", "tags": "system, linux, ansible, yaml, tips", "date": "2021-05-06 16:00:00 +0200", "snippet": "Check if a file exists and creates it if it doesn’tWith the stat module:- ansible.builtin.stat: path: pathToFile register: file_existsCan be used like that in a test, ie. create it if does not exist with the file module:- ansible.builtin.file: path: pathToFile state: touch when: file_exists.stat.exists == falseThe file can also be directly created when writing into if with the lineinfile or blockinfile modules with the create parameter set to yes. See next paragraphs.Check if a line exists in a fileWith the lineinfile module:- name: Check if the_line exists in the_file ansible.builtin.lineinfile: path: the_file regexp: '^the_line' state: absent # See https://docs.ansible.com/ansible/latest/user_guide/playbooks_checkmode.html check_mode: yes # See https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html # It tricks this task to be considered as never changing, so this playbook stays indempotent changed_when: false register: the_line_existence_testDirectly create the file with the create parameter set to yes:- name: Check if the_line exists in the_file ansible.builtin.lineinfile: path: the_file line: 'the_line' create: yesWrite a block in a fileWith the blockinfile module (here the file can also be directly created with the create parameter set to yes):- name: Writing lines in the the_file ansible.builtin.blockinfile: path: the_file marker: \"# {mark} ANSIBLE MANAGED BLOCK\" block: | line1 line2 backup: yes" }, { "title": "Personal stuff", "url": "/posts/misc-personal-stuff/", "categories": "Personal", "tags": "personal", "date": "2021-04-30 07:30:00 +0200", "snippet": "Personal shortcuts SlickRun: Maj + Win + Q Notes: Maj + Ctrl + W Everything: Alt + Maj + Q CopyQ: Alt + Maj + C" }, { "title": "Ansible loops", "url": "/posts/ansible-loops/", "categories": "System, Linux, Ansible, YAML, loop", "tags": "system, linux, ansible, yaml, tips, loop, loops", "date": "2021-04-29 14:30:00 +0200", "snippet": "LoopsSimple loopWith the given example list:my_list: - foo - bar - bazJust use the loop keyword:- ansible.builtin.debug: msg: item loop: \"{{ my_list }}\"Get loop’s extended infosJust use the loop_control keyword.Change loop variable name- ansible.builtin.debug: msg: list_item loop: \"{{ my_list }}\" loop_control: loop_var: list_itemGet loop’s indexesUse the loop_control keyword and set extended to true to get much more info.- include_tasks: taskThatUseLoopItem.yml loop: \"{{ my_list }}\" vars: # Current loop index (O indexed) loop_index_zero: \"{{ ansible_loop.index0 }}\" # Current loop index (1 indexed) loop_index_one: \"{{ ansible_loop.index }}\" loop_control: loop_var: list_item extended: yesAnsible loops reference" }, { "title": "Ansible inventories", "url": "/posts/ansible-inventories/", "categories": "System, Linux, Ansible, YAML, inventory", "tags": "system, linux, ansible, yaml, tips, inventory, inventories", "date": "2021-04-29 14:30:00 +0200", "snippet": "Inventory in YAML formatExample:---all: children: group_1: hosts: customAlias: ansible_host: \"realHostName.myDomain.com\" var_1: \"Foo\" customAlias_2: ansible_host: 192.168.1.2 var_2: 12345 group_2: hosts: \"realHostName2.myDomain.com\"Inventory in INI formatExcellent article on Ansible inventories - INI format onlyCheck an inventory syntaxExamples with the one given in YAML. To have a list:ansible-inventory -i inventory --listOutput:{ \"_meta\": { \"hostvars\": { \"customAlias\": { \"ansible_host\": \"realHostName.myDomain.com\", \"var_1\": \"Foo\" }, \"customAlias_2\": { \"ansible_host\": \"192.168.1.2\", \"var_2\": 12345 }, \"realHostName2.myDomain.com\": {} } }, \"all\": { \"children\": [ \"group_1\", \"group_2\", \"ungrouped\" ] }, \"group_1\": { \"hosts\": [ \"customAlias\", \"customAlias_2\" ] }, \"group_2\": { \"hosts\": [ \"realHostName2.myDomain.com\" ] }, \"ungrouped\": {}}To have a simplier graph:ansible-inventory -i inventory --graphOutput:@all: |--@group_1: | |--customAlias | |--customAlias_2 |--@group_2: | |--realHostName2.myDomain.com |--@ungrouped:Inventories to use in localIn INI formatMost basic:localhost ansible_connection=localIn YAML formatThe same one in YAML:all: children: ungrouped: hosts: localhost: ansible_connection: localConvert INI inventory in YAML oneThe YAML seems more easy to me to manage complex structures:ansible-inventory -i inventory_ini -y --list &gt; inventory_yamlInventory from Python scriptA dynamic inventory can be built from a Python script. This script has to: answer to a call with the --list argument that will be used in background by Ansible output an inventory in a JSON formatTwo useful links: Ansible official documentation Excellent blog article by Jeff GeerlingSimple example, built with the previous links (mostly Jeff Geerling’s one), that returns the previous inventory in a JSON format (note that the static JSON inventory can be build with the ansible-inventory -i inventory --list command). Note that: it also sends a mail with all the environment variables (useful in an AWX context) we have removed the ungrouped part (in order to avoid to have an ungrouped group in AWX)#!/usr/bin/env pythonfrom __future__ import print_functionfrom email.message import EmailMessageDOCUMENTATION = r'''Dynamic inventory (from the Ansible side) that returns a static JSON inventory.'''import osimport sysimport argparseimport smtplibimport datetimeimport timetry: import jsonexcept ImportError: import simplejson as jsonclass DynamicInventory(object): def __init__(self): self.inventory = {} self.read_cli_args() # Called with `--list`. if self.args.list: self.inventory = self.example_inventory() # Called with `--host [hostname]`. elif self.args.host: # Not implemented, since we return _meta info `--list`. self.inventory = self.empty_inventory() # If no groups or vars are present, return an empty inventory. else: self.inventory = self.empty_inventory() # Build the environment variables list to put then in a mail output = \"\" for a in os.environ: output +=('Var: {} Value: {} \\r\\n'.format(a, os.getenv(a))) self.send_mail(output) print(json.dumps(self.inventory)) def send_mail(self, body): address = 'john.doe@myDomain.com' msg = EmailMessage() msg.set_content(body) msg['Subject'] = 'Environment variables' msg['From'] = address msg['To'] = address # Send the message via our own SMTP server. s = smtplib.SMTP('smtp.myDomain.com', 25) s.send_message(msg) s.quit() # Example inventory for testing. def example_inventory(self): return { \"_meta\": { \"hostvars\": { \"customAlias\": { \"ansible_host\": \"realHostName.myDomain.com\", \"var_1\": \"Foo\" }, \"customAlias_2\": { \"ansible_host\": \"192.168.1.2\", \"var_2\": 12345 }, \"realHostName2.myDomain.com\": {} } }, \"all\": { \"children\": [ \"group_1\", \"group_2\" ] }, \"group_1\": { \"hosts\": [ \"customAlias\", \"customAlias_2\" ] }, \"group_2\": { \"hosts\": [ \"realHostName2.myDomain.com\" ] } } # Empty inventory for testing. def empty_inventory(self): return {'_meta': {'hostvars': {}}} # Read the command line args passed to the script. def read_cli_args(self): parser = argparse.ArgumentParser() parser.add_argument('--list', action = 'store_true') parser.add_argument('--host', action = 'store') self.args = parser.parse_args()# Get the inventory.DynamicInventory()" }, { "title": "Markdown", "url": "/posts/misc-markdown/", "categories": "Markdown, Misc, Tips", "tags": "markdown, misc, tips", "date": "2021-04-29 08:30:00 +0200", "snippet": "A backtick into backticksTwo bacticks to escape a single backtick:`` foo` `` produces foo`If there is a backtick at the beginning at the end or at the start, a space must be added:``foo` `` produces foo``` `foo` `` produces `foo``` `foo`` produces `fooEach additional backtick must be escaped with an additional backtick (so two \"`\" to escape one \"`\", three \"`\" to escape two \"`\", etc.):``` ``foo`` ``` produces ``foo`````` ```foo``` ```` produces ```foo```Sources: Meta Stack Exchange Daring fireballMarkwown referenceMarkdown Cheatsheet" }, { "title": "Chrome", "url": "/posts/misc-chrome/", "categories": "Chrome, Google", "tags": "chrome, google", "date": "2021-04-29 08:30:00 +0200", "snippet": "Reopen previously closed tabs in the order that they were closedMagical:Ctrl + Shift + tSource" }, { "title": "Git branch", "url": "/posts/git-branch/", "categories": "Development, Git, GitLab, GitHub", "tags": "development, git, gitlab, github", "date": "2021-04-29 08:30:00 +0200", "snippet": "Create branchesCreate a local branchSimply create a new branch and push it:git checkout -b myCustomBranchCreate a remote branchSimply create a new branch and push it directly to the remote repository:git checkout -b myCustomBranchgit push -u origin HEADGet a remote branchWe have a cloned a repository, and so only its master branch. It contains ie. a develop branch and we need it locally. To get it:git checkout developList branchesList local branches onlygit branch master* myCustomBranchList local and remote branchesWith -a argument:git branch -a master* myCustomBranch remotes/origin/HEAD -&gt; origin/master remotes/origin/master remotes/origin/myCustomBranchList with verbosityThe -v argument gives the commit the branch is on:git branch -v master a0ca238 Simple fix* myCustomBranch a0ca238 Simple fixList with more verbosityThe -vv argument gives the commit the branch is on and the corresponding remote branch:git branch -vv master a0ca238 [origin/master] Simple fix* myCustomBranch a0ca238 [origin/myCustomBranch] Simple fixCombine verbosity and remote branches detailsWith the combination of the -avv arguments:git branch -avv master a0ca238 [origin/master] Simple fix* myCustomBranch a0ca238 [origin/myCustomBranch] Simple fix remotes/origin/HEAD -&gt; origin/master remotes/origin/master a0ca238 Simple fix remotes/origin/myCustomBranch a0ca238 Simple fixDelete branchesDelete a local branchgit branch -d myCustomBranchDelete a remote branchgit push origin --delete myCustomBranchClone branchesClone a specific branchInstead of cloning a repo like:git clone myRepoSpecify the branch with -b:git clone -b neededBranch myRepo" }, { "title": "Ansible variables", "url": "/posts/ansible-variables/", "categories": "System, Linux, Ansible, YAML", "tags": "system, linux, ansible, yaml, tips", "date": "2021-04-21 08:00:00 +0200", "snippet": "Access a variable thanks to its nameExample playbook:---- name: \"Amazing playbook\" vars_files: - /vars/myVars.ymlThe variables file /vars/myVars.yml, example with a variable named with a host name:---myHost_1: unique_variable: \"Foo\"myHost_2: unique_variable: \"Bar\"Dynamic access in a playbook through the host name with vars dictionary:# Looping on hosts myHost_1 and myHost_2, it will contain \"Foo\" then \"Bar\"myDynamicVariable: \"{{ vars[inventory_hostname_short].unique_variable }}\" Access to a dynamic vars_files at the playbook levelWarning the facts are not accessible yet: vars_files: \"./vars/{{ inventory_hostname_short }}.yml\"Set a fact as undefinedJust leave it empty:vars: undefined_fact_trick:" }, { "title": "Ansible vault", "url": "/posts/ansible-vault/", "categories": "System, Linux, Ansible, Vault, AWX, Tower", "tags": "system, linux, ansible, vault, awx, tower", "date": "2021-04-16 08:00:00 +0200", "snippet": "Create an encrypted secret in Ansible vaultFirst steps: we have to chose an alias for an encryption key, ie. myEncryptionKey create an encryption key, ie. a 60 characters upper-case, lower-case and digits like hvtl6v0ZAbOF2U7hBdHJMBtqTw3KOJLMMXG3l2TiDU0JYwQun7ly1J7U5fdtOn a machine that has Ansible installed: in the ~/ansible directory, create a file that will contain the encryption key called ~/ansible/.vault_alias, ie. ~/ansible/.vault_myEncryptionKey copy the encryption key in this fileTo use it in AWX: create a credential of type Vault: in the field Vault Password copy the encryption key, in the Vault Identifier field the chosen alias, ie. myEncryptionKey in the template that has to decrypt a secret, add this credentialTo encrypt a secret, go back to the machine that has Ansible installed: create an ~/ansible.cfg file that contains the mapping encryptionKeyAlias@encryptionKeyFile, ie. myEncryptionKey@~/ansible/.vault_myEncryptionKey: # Entries encryptionKeyAlias@encryptionKeyFile has to be separated by comas [defaults] vault_identity_list = myEncryptionKey@~/ansible/.vault_myEncryptionKey create an ~/encrypt.sh script that will help to encrypt a secret and create a ready-to-use Ansible variable: #/bin/bash read -p \"Ansible variable name:\" ansible_variable_name echo read -s -p \"Secret to encrypt:\" secret_to_encrypt echo read -p \"Vault encryption key:\" encryption_key_id echo ansible-vault encrypt_string --encrypt-vault-id $encryption_key_id $secret_to_encrypt --name $ansible_variable_name Execute this script: Ansible variable name:test_variable Secret to encrypt: Vault encryption key:myEncryptionKey It will output: test_variable: !vault | $ANSIBLE_VAULT;1.2;AES256;myEncryptionKey 38383061353766373834393736653366623932303532626234316337336238613032636466666165 3636313632643561336262386337383637643436313866630a336338383531316435613266346236 35376633383334653932623739336333313237626135353735326666386130663765633961313037 3138633763323538340a643034336433313233613565323835613339333931303463623831653632 3736 Encryption successful This variable can be used in the playbook called by the template. " }, { "title": "Ansible tips", "url": "/posts/ansible-tips/", "categories": "System, Linux, Ansible, YAML", "tags": "system, linux, ansible, yaml, tips", "date": "2021-04-16 08:00:00 +0200", "snippet": "Ad-hoc modeUsed to test a module without having a playbook. Ie. with a ping on all hosts contained in the inventory file (-m is the argument for the module name):ansible -i inventory all -m pingSame thing with setup:ansible -i inventory all -m ansible.builtin.setupAd-hoc referenceFormat a patternExample with the input values:server_pattern: \"ldap://%s:%s\"server_uri: \"myServer.com\"server_port: 389final_server_uri: \"{{ server_pattern | format(server_uri, server_port) }}\"It will give:ldap://myServer.com:389Pad left an int with leading zerosWith two variables, one string and one int:var_int: 4var_string: \"5\"Two leading zeros examples with format template:- name: Pads left an int value ansible.builtin.set_fact: final_var_1: \"{{ '%02d' | format(var_int) }}\" # Here we first cast the var_string into an int in order to add the two variables final_var_2: \"{{ '%02d' | format(var_string | int + var_int) }}\"Final values:final_var_1 = \"04\"final_var_2 = \"09\"Classic factsOn a target host called myMachine.myDomain.com: ansible_hostname = myMachine ansible_fqdn = myMachine.myDomain.comMagic variablesOn a target host called myMachine.myDomain.com: inventory_hostname_short = myMachine inventory_hostname = myMachine.myDomain.comMagic variables vs. factsSpecial variablesMagic variables + classic facts = special variablesSpecial variables referenceCheck if a packages is installed (ie. httpd for Apache)- name: Gettings package facts package_facts: changed_when: false- name: Creating a fact for Apache installation status ansible.builtin.set_fact: apache_is_installed: \"{{ ('httpd' in ansible_facts.packages) | ternary(1, 0) }}\" changed_when: falsePackage facts reference" }, { "title": "LDAP tips", "url": "/posts/ldap-tips/", "categories": "System, Linux, LDAP", "tags": "system, linux, ldap, tips", "date": "2021-04-16 08:00:00 +0200", "snippet": "Documentations ldapsearch ldapmodifyLDAP search Useful documentationUsage:ldapsearch [options] [filter [attributes...]]With: filter: RFC 4515 compliant LDAP search filter attributes: whitespace-separated list of attribute descriptionsOptions: Search options: -b: base DN -LLL: print responses in LDIF format without comments and version -s: search scope (so base, one, sub or children) Other options: -D: bind DN -h: LDAP server host -p: LDAP server port -w: bind password -W: prompt for bind password -z: size limit (max entries returned). 0 means no limit Example:ldapsearch -LLL -h myLdapServerHost -p 389 -D \"cn=Directory Manager,o=myRoot\" -W -b \"ou=mySubOu,o=myRoot\" -s base \"uid=doe0001\" cn titleExample with a password kept in the session:read myLdapPasswordldapsearch -LLL -h myLdapServerHost -p 389 -D \"cn=Directory Manager,o=myRoot\" -w \"$myLdapPassword\" -b \"ou=mySubOu,o=myRoot\" -s base \"uid=doe0001\" cn titleBy default, results are displayed on 80 characters. To have full lines, just use the -o ldif-wrap=no option. The option is ldif_wrap since RHDS 10, but to maintain compatibility with RHDS 9 tools, we use the “old” ldif-wrap syntax that is still compatible.LDAP modify Useful documentationCan be also used with ldapadd commandOptions: Search options: -n: kind of demo mode, shows what should be done but does not do it -a: to add new entries (this flag is alway set when called with ldapadd) -c: continuous mode, does not stop on errors -f: uses an input file instead of the standard input Delete an attributedn: cn=myEntry,o=myBasechangetype: modifydelete: uniqueMemberHints : a pipe can be used to input a LDIF content, ie.:command_that_generates_ldif | ldapmodify ...Modify several attributes at the same timeA - is needed to separate different attributes (each one with the needed add, replace or delete):dn: cn=XXX,ou=YYY,o=ZZZchangetype: modifyadd: uniqueMemberuniqueMember: uid=111,ou=BBB,ou=YYY,o=ZZZuniqueMember: uid=112,ou=BBB,ou=YYY,o=ZZZuniqueMember: uid=113,ou=BBB,ou=YYY,o=ZZZ-replace: otherAttributeotherAttribute: uid=114,ou=BBB,ou=YYY,o=ZZZotherAttribute: uid=115,ou=BBB,ou=YYY,o=ZZZ-delete: yetAnotherAttributeyetAnotherAttribute: uid=116,ou=BBB,ou=YYY,o=ZZZ" }, { "title": "Windows terminal", "url": "/posts/tools-windows-terminal/", "categories": "Tools", "tags": "tools, windows, terminal", "date": "2021-04-04 15:00:00 +0200", "snippet": "Change the default opened terminalLocate the defaultProfile line and set its value with the needed terminal GUID:{ \"defaultProfile\": \"{b4be9505-f320-4a0f-b648-3e51f03cd66c}\" }{ \"list\": [ { \"guid\": \"{93eb43cd-0a92-4b6d-99dc-b3fb64e1536c}\", \"name\": \"Windows PowerShell\", \"commandline\": \"powershell.exe\", \"hidden\": false }, { \"guid\": \"{b4be9505-f320-4a0f-b648-3e51f03cd66c}\", \"name\": \"My custom powershell installation\", \"commandline\": \"powershell.exe\", \"hidden\": false, \"startingDirectory\": \"C:\\\\MyCustomDirectory\", \"icon\": \"💣\" } ]}Hint: get a GUIDChange the distribution and the user to open the WSL withIn the WSL entry, change the commandline parameter value: -d: the distribution’s name -u: the user’s name{ \"commandline\": \"wsl -d distributionName -u userName\" }" }, { "title": "WSL tips", "url": "/posts/wsl-tips/", "categories": "System, WSL", "tags": "system, wsl, powershell, linux, tips", "date": "2021-04-02 14:00:00 +0200", "snippet": "List installed distributionswsl --list --verboseExample output: NAME STATE VERSION* Debian1 Running 1 Debian2 Stopped 1 Debian3 Stopped 2 Debian4 Installing 1From here we consider that we have a distribution called Debian1.Start distributionwsl -d Debian1With a specific user:wsl -d Debian1 -u myUserStop distributionwsl -t Debian1Export a distribution imagewsl --export &lt;distributionName&gt; &lt;tarPath&gt;Example:wsl --export Debian1 C:\\myTarPath\\Debian1.tarImport a distribution imagewsl --import &lt;distributionName&gt; &lt;installationPath&gt; &lt;tarPath&gt; --version &lt;wslVersion&gt;Example importing the Debian1 image to a new ditribution called Debian2:wsl --import Debian2 C:\\myInstallationPath\\Debian2 C:\\myTarPath\\Debian1.tar --version 1Delete a distributionFirst unregister it:wsl --unregister &lt;distributionName&gt;wsl --unregister Debian1Then physically delete its files:Remove-Item &lt;installationPath&gt; -Force -RecurseRemove-Item C:\\myInstallationPath\\Debian1 -Force -RecurseChange a distribution WSL versionTo change an installed distribution version:wsl --set-version &lt;distributionName&gt; &lt;versionNumber&gt;wsl --set-version Debian2 2Note that the version can be upgraded or downgraded (from 1 to 2 or from 2 to 1).To change the default version for all new installed distributions:wsl --set-default-version &lt;versionNumber&gt;wsl --set-default-version 2Change default distributionExample output of the wsl --list --verbose command: NAME STATE VERSION* Debian1 Running 1 Debian2 Stopped 1 Debian3 Stopped 2 Debian4 Installing 1* indicates the default one. To change it:wsl --setdefault &lt;distributionName&gt;wsl --setdefault Debian2New output: NAME STATE VERSION* Debian2 Stopped 1 Debian1 Running 1 Debian3 Stopped 2 Debian4 Installing 1Restart background WSL Windows serviceIf everything is screwed up, just reboot the associated service which is called LxssManager. Trough powershell:Get-Service LxssManager | Restart-ServiceCreate a partition Only valid on WSL 2!WSL uses virtual disk, so to have a “free” disk to mount a partition on, just launch several instances to have multiple virtual disks. Check the running ones with wsl --list --verbose: NAME STATE VERSION* DebianWSL1 Stopped 1 DebianAgain Stopped 1 DebianIIQ Running 2 RockyLinux Stopped 2 wsl-vpnkit Running 2 DebianAnsible4 Stopped 1 DebianAnsibleLdap Stopped 1 DebianWSL2 Running 2 DebianDynatrace Stopped 2Identify the disks used by each instance with lsblk. In this example we are on the instance that runs on sdb:NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 256G 0 disksdb 8:16 0 256G 0 disk /sdc 8:32 0 256G 0 disksdd 8:48 0 256G 0 disksde 8:64 0 256G 0 disksdf 8:80 0 256G 0 diskShutdown a selected one (the virtual disk will still be present), here for example the one that runs on sdf, and a partition can be created on this disk from another WSL instance." }, { "title": "AWX tips", "url": "/posts/ansible-awx-tips/", "categories": "System, Linux, Ansible, AWX, Tower", "tags": "system, linux, ansible, awx, tower, tips", "date": "2021-03-25 14:00:00 +0100", "snippet": "Here we consider that we have two hosts, host_1 and host_2.TheoryA few things to know: a project is a link to a repository that can contains playbooks, inventories, variables files, Python scripts, etc. a job template is linked with a project, a given playbook (from this project), a given inventory and credentials. Variables can be set there too a template workflow is a set of job templatesAccess to a variable defined in a job templateAdditional variables defined in the job template:---runtime_var: \"Hi I'm a runtime variable from a job template\"# This is used to be access dynamically to a variable that belongs to a unique hosthost_1: message: \"FOO\"host_2: message: \"BAR\"Access to these variables through the playbook:---- name: \"Dummy playbook\" # ... tasks: - name: Display runtime variable debug: msg: '{{ runtime_var }}' - name: Display specific dynamic host variable from job template debug: msg: \"My message {{ vars[ansible_hostname].message }}\"Access to a variable defined in a hostHost variable:---host_var: \"BAZ\"Access to this variable through the playbook:---- name: \"Dummy playbook\" # ... tasks: - name: Display host variable debug: msg: \"Defined with the host: {{ hostvars[inventory_hostname].host_var }}\"Access to a variable defined in a inventoryInventory variable:---inventory_var: \"BOO\"Access to this variable through the playbook:---- name: \"Dummy playbook\" # ... tasks: - name: Display inventory variable debug: msg: \"Defined with the inventory: {{ inventory_var }}\"Access to a variables file through vars_filesAWX copies the playbook files into its own structure, so a relative path must be used:---vars_files: ./vars/myFile.ymlDynamic inventoryA “dynamic” inventory comes from a repository, thus it can be a yaml file or the result of a Python script execution.To use it : create a project mapped to the repository create an inventory: create a “Sourced from a Project” source in this inventory to use the target file/script the the inventory can be used in another job templateInventory from scriptIf an inventory comes from a script, ie. Python or bash, this script must be marked as executable on the repository side. To do this (source):git update-index --chmod=+x path/to/fileVariables can be defined in the inventory’s source, ie.:---inventory_source_var: \"Foo\"This variable is set as an environment variable and can be used directly in the target script (see in the target langage’s documentation how to use environment variables)." }, { "title": "Sed", "url": "/posts/linux-sed/", "categories": "System, Linux", "tags": "system, linux, shell, tips, sed", "date": "2021-03-12 14:00:00 +0100", "snippet": "Remove line(s) in a file with a regex-i for in-place editing, d deletes the line(s) if it matches:sed -i '/regexPattern/d' myFileRemove all occurences of a pattern in a file with a regex-i for in-place editing, s (for substitute) and g (for global) for all matches:sed -i 's/regexPattern/replacementPattern/g' myFileEscape the good characters for the replacementThere’s a tool for thatGood tutorialOn tutorialspoint" }, { "title": "Vim", "url": "/posts/linux-vim/", "categories": "System, Linux", "tags": "system, linux, shell, tips, vim, vi", "date": "2021-03-11 14:00:00 +0100", "snippet": "See an option value:set option?Example::set paste?nopasteColumn mode edition ^V to go to to column mode (displays -- VISUAL BLOCK --) select the columns shift I to go to insert mode (displays -- INSERT --) Type what you need double escapeDeletionsCommon deletion operations : current line: type dd current word: type dw from cursor to end of line: type d$ or D delete all file content: use gg to go to the beginning of the file, then type dGPaste from outside without breaking the indentationJust activate the paste option (paste in Vim doc) to paste unmodified the external text::set pastePaste the text and reactivate the nopaste option::set nopasteSee line breaks and carriage returnsIt’s about the list and nolist options::set listTo hide them::set nolist.vimrc~/.vimrc is a pseudo equivalent of system’s ~/.bashrc, it’s user’s specific configuration. Example::set nocompatible:syntax onMore than useful linksDisplay the current Vim environmentVim Tips Wiki" }, { "title": "Git tips", "url": "/posts/git-tips/", "categories": "Development, Git, GitLab, GitHub", "tags": "development, git, gitlab, github", "date": "2021-02-26 14:30:00 +0100", "snippet": "Clone using a GitLab tokengit clone https://myToken@myGitServer/myRepo.gitGreat .gitignore base for Visual StudioGreat file to start withCertificate problemThe following error can occur: SSL certificate problem: unable to get local issuer certificate. It can happen when it’s not the Windows certificate store that is used.Check the http.sslBackend value in the config. If openssl is set, this is not good (it means that the openssl bundle certificate strop is used). It’s better to have the schannel set:http.sslbackend=schannelDetails on this SO post. Note that it’s not possible from WSL.See global .gitconfig documentation for more elements.See changes on a filegit diff myFileExample output:- Old value+ New valueSee commit historygit logExample output:commit a0ca238d7a33621b96f8cf9778575ddfdad04515 (HEAD -&gt; myCustomBranch, origin/myCustomBranch, origin/master, origin/HEAD, master)Author: John Doe &lt;john.doe@google.com&gt;Date: Fri Apr 23 09:57:16 2021 +0200 Simple fixcommit 9d0468b2a9a24229826be5493c0a81a996eb49b9Author: John Doe &lt;john.doe@google.com&gt;Date: Thu Apr 15 14:15:04 2021 +0200 Copy from last SVN versioncommit 4796c475876bd1472f2681df0a8fa74e7fb776d5Author: John Doe &lt;john.doe@google.com&gt;Date: Mon Apr 12 14:25:15 2021 +0000 Initial commitTo have a more graphical version:git log --graphTo have a oneline decorated version:git log --oneline --decorate --graph --allExample output:* a0ca238 (HEAD -&gt; myCustomBranch, origin/myCustomBranch, origin/master, origin/HEAD, master) Simple fix* 9d0468b Copy from last SVN version* 4796c47 Initial commitSee commit history for a given filegit log myFileExample output:commit 9d0468b2a9a24229826be5493c0a81a996eb49b9Author: John Doe &lt;john.doe@google.com&gt;Date: Thu Apr 15 14:15:04 2021 +0200 Copy from last SVN versionProblems with CRLF/LF on WindowsWindows use CRLF whereas files are with LF on a repository. So, when commiting from Window, we have warnings like:warning: LF will be replaced by CRLF in myFileThe file will have its original line endings in your working directoryIt’s possible to have an automatic conversion instead of this warning message. To correct it, add a value in the project’s configuration (or in the global one):git config --local core.autocrlf inputGreat explanation and details on SO hereAvoid to type token at each operation to GitlabCheck your local configuration:git config --local --listThe following line:remote.origin.url=https://myRepoHost.com/myRepo.gitThe user and its associated token have to be added:git config --local remote.origin.url https://myUser:myToken@myRepoHost.com/myRepo.gitIn order to have in the configuration:remote.origin.url=https://myUser:myToken@myRepoHost.com/myRepo.git" }, { "title": "Standard directories and files", "url": "/posts/linux-standard-directories-and-files/", "categories": "System, Linux", "tags": "system, linux, shell", "date": "2020-10-29 11:30:00 +0100", "snippet": "System directories /etc/group: groups definition /etc/passwd: users definition /etc/skel: directory with files templates (ie. .bashrc) to be copied when creating a home directory /etc/shadow: contains users hashed passwords /etc/login.defs: several configuration settings, ie. method used to create passwords hashs" }, { "title": "PowerShell tips", "url": "/posts/powershell-tips/", "categories": "Development, PowerShell", "tags": "development, powershell, tips", "date": "2020-10-29 11:30:00 +0100", "snippet": "Change the console titleVery useful when there are many windows opened (or in a script):$title = \"My new awesome title\"$host.UI.RawUI.WindowTitle = $titleList profile filesprofile.ps1 is a pseudo equivalent of Linux’s .bashrc, it’s user’s specific configuration. It has different levels: to see all files:$PROFILE | Get-Member -MemberType noteproperty | Format-ListOutput example:TypeName : System.StringName : AllUsersAllHostsMemberType : NotePropertyDefinition : string AllUsersAllHosts=C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\profile.ps1TypeName : System.StringName : AllUsersCurrentHostMemberType : NotePropertyDefinition : string AllUsersCurrentHost=C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\Microsoft.PowerShell_profile.ps1TypeName : System.StringName : CurrentUserAllHostsMemberType : NotePropertyDefinition : string CurrentUserAllHosts=C:\\Users\\myUser\\Documents\\WindowsPowerShell\\profile.ps1TypeName : System.StringName : CurrentUserCurrentHostMemberType : NotePropertyDefinition : string CurrentUserCurrentHost=C:\\Users\\myUser\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1Add a permanent aliasThrough the profile.ps1, example:Set-Alias ll Get-ChildItemSet-Alias documentationEscape quotesVariables need to be in double quotes \"\" to be interpreted, ie:$foo = \"FOO\"$bar = '$foo'$baz = \"$foo\"Write-Host $barWrite-Host $bazOutput will be:$fooFOOSo if we need a double quote insided a double quoted string, we can escape them with \"`\":$foo = \"FOO\"$bar = \"Hello `\"$foo`\"\"Write-Host $barOutput will be:Hello \"FOO\"Get command outputSimply call ithe command the easiest way and put it in a variable:$jwt = java -jar myJar.jar argumentWrite-Host $jwtCopy to the clipboardUse the Set-Clipboard cmdlet with the -Value argument:$jwt = java -jar myJar.jar argumentSet-Clipboard -Value $jwtSet-Clipboard documentationGet a certificate thumbprintExample with a certificate which subject is CN=HOSTNAME (aka the self-signed certificate):$hostname = hostname$certificateStorePath = \"Cert:\\LocalMachine\\My\"$serverCertificateThumbprint = Get-ChildItem $certificateStorePath | Where-Object Subject -eq \"CN=$hostname\" | Select-Object -ExpandProperty ThumbprintOther method:$certificateStorePath = \"Cert:\\LocalMachine\\My\"$serverCertificateThumbprint = Get-ChildItem $certificateStorePath | Where-Object {$_.Subject -eq \"CN=$($env:COMPUTERNAME)\"} | Select-Object -ExpandProperty ThumbprintSelect-Object documentationGive read rights on this certificateSource$hostname = hostname$certificateStorePath = \"Cert:\\LocalMachine\\My\"$certificateThumbprint = 'abcdefb5956babcdefa71dabcdeffac5e5abcdef'# Looking for the needed certificate$certificate = Get-ChildItem $certificateStorePath | Where-Object Thumbprint -eq $certificateThumbprint# Getting its private key$privateKey = [System.Security.Cryptography.X509Certificates.RSACertificateExtensions]::GetRSAPrivateKey($certificate)$containerName = ''if ($privateKey.GetType().Name -ieq \"RSACng\") { $containerName = $privateKey.Key.UniqueName}else { $containerName = $privateKey.CspKeyContainerInfo.UniqueKeyContainerName} $keyFullPath = $env:ProgramData + \"\\Microsoft\\Crypto\\RSA\\MachineKeys\\\" + $containerName;if (-Not (Test-Path -Path $keyFullPath -PathType Leaf)) { throw \"Unable to get the private key container to set permissions.\"}# Get the current ACL of the private key$acl = (Get-Item $keyFullPath).GetAccessControl() # Add the new ACE to the ACL of the private key# Imagine we give rights to two groups$certificateGroup = 'IIS_APPPOOLS_certificate_user'$iisGroup = 'IIS_IUSRS'$accessRulePoolGroup = New-Object System.Security.AccessControl.FileSystemAccessRule($certificateGroup, \"Read\", \"Allow\")$accessRuleIisGroup = New-Object System.Security.AccessControl.FileSystemAccessRule($iisGroup, \"Read\", \"Allow\")$acl.AddAccessRule($accessRulePoolGroup);$acl.AddAccessRule($accessRuleIisGroup);# Write back the new ACLSet-Acl -Path $keyFullPath -AclObject $acl;Compute a file hashWith the Get-FileHash cmdlet. Default hash algorithm (if not specified with -Algorithm argument) is SHA256.To get a default SHA256 hash:Get-FileHash C:\\myFile.txtOutput is:Algorithm Hash Path--------- ---- ----SHA256 BFF9360D9A14AAE7B8CC4D829C6570B3FA72925E0ECF037582DEAEAEAA8E268C C:\\myFile.txtTo get a MD5 hash and display only the hash:Get-FileHash C:\\myFile.txt -Algorithm MD5 | Select-Object HashOutput is:Hash----BFF9360D9A14AAE7B8CC4D829C6570B3FA72925E0ECF037582DEAEAEAA8E268CTo get a MD5 hash and get only the hash:Get-FileHash C:\\myFile.txt -Algorithm MD5 | Select-Object -ExpandProperty HashOutput is:BFF9360D9A14AAE7B8CC4D829C6570B3FA72925E0ECF037582DEAEAEAA8E268CTernary operationLike the traditional condition ? true : false:$foo = \"Fake foo\"$bar = if ($foo -eq \"Foo\") { \"It's foo!\" } else { \"It's not foo...\" }Write-Host $barOutput:It's not foo..." }, { "title": "Parameters", "url": "/posts/powershell-parameters/", "categories": "Development, PowerShell", "tags": "development, powershell, parameters", "date": "2020-10-29 11:30:00 +0100", "snippet": "WIPTODO 1TODO 2TODO 3" }, { "title": "SSH", "url": "/posts/linux-ssh/", "categories": "System, Linux", "tags": "system, linux, shell, ssh, ansible", "date": "2020-10-29 09:30:00 +0100", "snippet": "Create a key -t public key algorithm (rsa, dsa, ecdsa, ed25519) -b key size (optional) -C comment that will be added at the end of the public keyssh-keygen -t rsa -C user@machineIt will generate two files: the private key file, ie. my_key:-----BEGIN OPENSSH PRIVATE KEY-----the_private_key-----END OPENSSH PRIVATE KEY----- the public key file, ie. my_key.pub:ssh-rsa the_public_key user@machineCopy the public key on a target server we need to authenticate tossh-copy-id -i my_key.pub user@target.serverList actual SSH keysssh-add -lWay to keep the keys for Ansible when the session is closedIn the .bashrc file:# It uses this specific file to keep the infos between sessionsSSH_ENV=\"$HOME/.ssh/agent_environment\"function start_agent { echo \"Initializing new SSH agent...\" # The ssh-agent command output looks like (this is commands to set certain environment variables in the shell): # SSH_AUTH_SOCK=/tmp/ssh-sacIg0yhB3Ap/agent.1419789; export SSH_AUTH_SOCK; # SSH_AGENT_PID=1419790; export SSH_AGENT_PID; # echo Agent pid 1419790; # So it keeps it a file and the sed comments the line that starts with \"echo\" /usr/bin/ssh-agent | sed 's/^echo/#echo/' &gt; \"${SSH_ENV}\" echo succeeded chmod 600 \"${SSH_ENV}\" # With the dot command it executes the ouput of the ssh-agent command . \"${SSH_ENV}\" &gt; /dev/null /usr/bin/ssh-add;}# Check if the file existsif [ -f \"${SSH_ENV}\" ]; then # If so, it reexecutes its contents and keep the previous agent with its existing PID . \"${SSH_ENV}\" &gt; /dev/null # Check if the given agent is running with the correct PID ps -ef | grep ${SSH_AGENT_PID} | grep ssh-agent$ &gt; /dev/null || { # If no, it starts a new one start_agent; }else start_agent;fiSSH logs on server (RHEL)Located in /var/log/secure.ReferencesSee: ssh-keygen reference ssh-copy-id reference ssh-add reference ssh-agent reference Dot command" }, { "title": "Conditions and tests", "url": "/posts/bash-conditions-and-tests/", "categories": "System, Linux, Bash, Shell", "tags": "system, linux, bash, shell, tests, conditions", "date": "2020-10-29 09:30:00 +0100", "snippet": "Conditions -d returns true if a directory exists -e returns true if a file exists -o perform a logical or between two tests -z returns true if the given command returns an empty string -L checks if a symlink existsif [ -z \"`grep \"DIRECTORY\" /etc/sudoers`\" ]GNU conditions manpageBSD conditions manpageMore conditionsTest command &amp;&amp;test cmd1 &amp;&amp; cmd2cmd1 is executed, if its return code equals 0 then cmd2 is executed ||test cmd1 || cmd2cmd1 is executed, if its return code is different than 0 then cmd2 is executedtest command" }, { "title": "Execute as", "url": "/posts/tsql-execute-as/", "categories": "Development, T-SQL", "tags": "development, t-sql, sqlserver, database", "date": "2020-10-29 08:30:00 +0100", "snippet": "Execute a query as a different user/loginUseful to debug rights problems:EXECUTE AS LOGIN = 'myLogin'; -- Display current execution context and verify the execution context is now myLogin SELECT SUSER_NAME(), USER_NAME(); -- Login1 sets the execution context to myUser. EXECUTE AS USER = 'myUser'; -- Display current execution context and verify the execution context is now myUser SELECT SUSER_NAME(), USER_NAME(); See: full documentation" }, { "title": "Generic informations", "url": "/posts/tsql-generic-informations/", "categories": "Development, T-SQL, PowerShell", "tags": "development, t-sql, sqlserver, database, column, powershell", "date": "2020-10-29 08:30:00 +0100", "snippet": "Check if a connection is OK or not$connection = New-Object System.Data.SqlClient.SqlConnection$connection.ConnectionString = 'data source=mySource;initial catalog=myDatabse;persist security info=True;user id=myUser;password=myPassword;MultipleActiveResultSets=True;App=EntityFramework'$connection.Open()$connection.Close()No output if the connection is OK, otherwise there will be an error on stderr.List installed instances with PowerShellOn the server, querying the registry with Get-ItemProperty:$instances = (Get-ItemProperty 'HKLM:\\SOFTWARE\\Microsoft\\Microsoft SQL Server').InstalledInstancesWrite-Host $instances Output:MYINSTANCE1MYINSTANCE2List all databasesPerform a query on the master.dbo.sysdatabases table:SELECT [name] FROM master.dbo.sysdatabasesNon-user databases can be excluded with the following WHERE clause:SELECT [name] FROM master.dbo.sysdatabases WHERE [name] NOT IN ('master', 'tempdb', 'model', 'msdb') Reporting services databases can also be excluded.This exclusion can also be done on the dbid field:SELECT [name] FROM master.dbo.sysdatabases WHERE [dbid] &gt; 4 dbid between 1 and 4 are system databases, dbid between 5 and 6 are usually report server databases.List tables from the current databaseNote that there is a lot of ways to achieve this.SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'Create operatorWith sp_add_operator:EXEC msdb.dbo.sp_add_operator @name=N'John Doe', @enabled=1, @weekday_pager_start_time=90000, @weekday_pager_end_time=180000, @saturday_pager_start_time=90000, @saturday_pager_end_time=180000, @sunday_pager_start_time=90000, @sunday_pager_end_time=180000, @pager_days=0, @email_address=N'john.doe@foo.com', @category_name=N'[Uncategorized]'GOAdd rights to select the operatorsThe user must exist msdb database:USE [msdb]GOGRANT SELECT ON [dbo].[sysoperators] TO [myUser]GOAdd rights to execute a specific stored procedureIe. with sp_send_dbmail:USE [msdb]GOGRANT EXECUTE ON [dbo].[sp_send_dbmail] TO [myUser]GOMailingSee database mail configurationRight click on Management &gt; Database Mail, select Configure Database Mail.List mail profilesWith the sysmail_help_profile_sp procedure:EXEC msdb.dbo.sysmail_help_profile_sp;Be allowed to send mailTHe best way is to be part of the DatabaseMailUserRole role:USE [msdb]GOEXEC sp_addrolemember N'DatabaseMailUserRole', N'myUser'GO-- Then the user is mapped to a profileEXECUTE msdb.dbo.sysmail_add_principalprofile_sp @profile_name = 'myProfile', @principal_name = 'myUser', @is_default = 1 ;Send mailWith the msdb.dbo.sp_send_dbmail procedure:EXEC msdb.dbo.sp_send_dbmail @profile_name = 'MyProfile', @recipients = 'my@email.com', @subject = 'subject', @body_format = 'HTML', @body = 'body'Scripts collectionUseful collection." }, { "title": "Ulimit", "url": "/posts/linux-ulimit/", "categories": "System, Linux", "tags": "system, linux, shell, ulimit", "date": "2020-10-28 09:10:00 +0100", "snippet": "ulimit is a command that enables to put limits on the amount of various system resources available to a user process (ie. max number of open files, the priority to run user process with, etc.).If we need theses values to be persistent after reboots, just set the ulimit values in the /etc/security/limits.conf file or in a specific file.conf file in the /etc/security/limits.d directory.See all the current user limits# H for hard limits, S for soft limits, a means all$ ulimit -Sa$ ulimit -HaOutput example:core file size (blocks, -c) unlimiteddata seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 63264max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 262144pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) unlimitedcpu time (seconds, -t) unlimitedmax user processes (-u) 63264virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimitedSee a specific value for the current userulimit -SuOutput example:63264See all the limits for another usersu - user -c \"ulimit -a\"" }, { "title": "Git config", "url": "/posts/git-config/", "categories": "Development, Git", "tags": "development, git", "date": "2020-09-18 14:30:00 +0200", "snippet": "System config location (.gitconfig file)Linux systems: /etc/gitconfigIn the installation folder in Windows, ie. C:/Program Files/Git/etc/gitconfigGlobal config locationHome directory in Linux systems: ~/.gitconfigWindows: %USERPROFILE%Local config location.git/config or .git\\config in the current repository folderList the config valuesWe can add the --show-origin argument to see the file’s location:git config --listList the global values only:git config --global --listList the local values only:git config --local --listAdd a config valueExample adding a user name (name is a property of the user’s section) in the global section:git config --global user.name Maxime GaultRemove a config valueA global one:git config --global --unset http.sslBackendA value can be configured in several files, the last one is used.More info on official website" }, { "title": "Tips", "url": "/posts/linux-tips/", "categories": "System, Linux", "tags": "system, linux, shell, tips, symlink, pwd, printenv, env, set, unset, password, sudo, sudoers, user, group, find", "date": "2020-09-18 14:00:00 +0200", "snippet": "RedirectionsUse &gt; to redirect an output to a file (&gt;&gt; to append).To redirect special handles: file descriptor 0 is the standard input (stdin) file descriptor 1 is the standard output (stdout) file descriptor 2 is the standard error (stderr)So (source): &gt; file redirects stdout to file 1&gt; file redirects stdout to file 2&gt; file redirects stderr to file &amp;&gt; file redirects stdout and stderr to file (equivalent of older 2&gt;&amp;1 &gt; file) &gt; file 2&gt;&amp;1 redirects stdout and stderr to fileExamples:myCommand &gt; myFile (equivalent of myCommand 1&gt; myFile) will redirect its standard output to myFilemyCommand 2&gt; myFile will redirect its standard error to myFilemyCommand 2&gt;&amp;1 &gt; myFile will redirect its standard error to its standard output, then its standard output to myFileWarning: 2&gt;1 would result in a 1 file creation, the &amp; is important and indicates that what is next is a file descriptor and not a file./dev/null is the special “null device” used to redirect a useless content, ie. myCommand 2&gt;&amp;1 /dev/null.Find somethingfind &lt;base&gt; -name &lt;name&gt;Example:find / -name *.pyfind / -name *.py 2&gt;/dev/nullCreate a symlinkln -s ~/foo/bar/baz ~/mySymLinkPrint Working Directory a.k.a. pwdWhen you’ve followed a symlink, pwd shows by default the logical path, ie:cd ~/mySymLinkpwd~/mySymLinkIf you need the real physical path, use the -P argument:pwd -P~/foo/bar/bazEnvironment variablesList them:printenv Add one:export MY_VAR Display one:echo $MY_VAR Remove one:unset MY_VAR Read a password from the console and avoid to have it in the bash_historyExample setting a proxy in an environment variable:read -s passexport my_var=\"http://user:$pass@my_proxy.com:1234\"Validate a sudoers fileFor a user user that has a specific sudoers /etc/sudoers.d/user file:visudo -cf /etc/sudoers.d/userError output example:&gt;&gt;&gt; /etc/sudoers.d/user: syntax error near line 2 &lt;&lt;&lt;parse error in /etc/sudoers.d/user near line 2OK output example:/etc/sudoers.d/user: parsed OKWatchThe watch command executes a program periodically, showing output fullscreenwatch 'ps -ef | grep slapd'Every 2.0s: ps -ef | grep slapd myServer: Thu Nov 25 09:26:31 2021rhds 1489 1 0 Nov11 ? 02:19:10 /usr/sbin/ns-slapd -D /etc/mydirsrv/slapd-01 -i /run/mydirsrv/slapd-01.pidroot 901137 900625 0 09:26 pts/1 00:00:00 watch ps -ef | grep slapdroot 901156 901137 0 09:26 pts/1 00:00:00 watch ps -ef | grep slapdroot 901157 901156 0 09:26 pts/1 00:00:00 sh -c ps -ef | grep slapdroot 901159 901157 0 09:26 pts/1 00:00:00 grep slapdnetstatContinuous netstat:netstat -cSee opened connections, with: -t: TCP -u: UDP -a: all (to include sockets in listen state)netstat -aColorsShow colors on a ls with the argument --color=auto:ls --color=autoSo the following permanent aliases can be added in the .bash_aliases file:alias ls='ls --color=auto'alias ll='ls -l'alias la='ls -la'TarArchive and compress (in the same time, so create a tgz) a folder:tar cfvz myDirectoryArchived.tgz myDirectory/GrepShow lines: before the match with -B after the match with -Agrep -B 5 -A 3 'word' fileToLookInColor the needed word with --color:grep --color 'word' fileToLookInRecursive in a directory with -r:grep -r 'word' directoryToLookIn/*EpochEpoch converter" }, { "title": "Locale", "url": "/posts/linux-locale/", "categories": "System, Linux", "tags": "system, linux, shell, locale", "date": "2020-09-17 15:30:00 +0200", "snippet": "See system localelocalectlOutput example: System Locale: LANG=fr_FR.UTF-8 VC Keymap: fr-oss X11 Layout: fr X11 Variant: oss changer la localeChange system localelocalectl set-locale LANG=en_US.UTF-8localectlOutput example: System Locale: LANG=en_US.UTF-8 VC Keymap: fr-oss X11 Layout: fr X11 Variant: oss" }, { "title": "Certificates", "url": "/posts/csharp-certificates/", "categories": "Tools", "tags": "development, c#, certificate", "date": "2020-09-17 15:30:00 +0200", "snippet": "WIP" }, { "title": "Various system informations", "url": "/posts/linux-various-system-informations/", "categories": "System, Linux", "tags": "system, linux, shell, version, python", "date": "2020-09-15 10:30:00 +0200", "snippet": "Know the distribution name and versionA way:cat /etc/*-releaseOutput example:NAME=\"Red Hat Enterprise Linux\"VERSION=\"8.2 (Ootpa)\"ID=\"rhel\"ID_LIKE=\"fedora\"VERSION_ID=\"8.2\"PLATFORM_ID=\"platform:el8\"PRETTY_NAME=\"Red Hat Enterprise Linux 8.2 (Ootpa)\"ANSI_COLOR=\"0;31\"CPE_NAME=\"cpe:/o:redhat:enterprise_linux:8.2:GA\"HOME_URL=\"https://www.redhat.com/\"BUG_REPORT_URL=\"https://bugzilla.redhat.com/\"Another way:hostnamectlOutput example: Static hostname: myHostName Icon name: computer-vm Chassis: vm Machine ID: 84044124ac3b46cb83b39110745763a9 Boot ID: 65460d4645724ecabf3be02873edf0f0 Virtualization: vmware Operating System: Red Hat Enterprise Linux 8.2 (Ootpa) CPE OS Name: cpe:/o:redhat:enterprise_linux:8.2:GA Kernel: Linux 4.18.0-193.el8.x86_64 Architecture: x86-64Know the installed Python versionA way:python --versionOutput example:python 2.0.0Another way:python -VOutput example:python 3.0.0" }, { "title": "Certificates theory", "url": "/posts/theory-certificates/", "categories": "Theory", "tags": "theory, certificate", "date": "2020-09-01 17:00:00 +0200", "snippet": "Duplicated from TutorialsTeacherSSL Certificate FormatsAn SSL Certificate is essentially an X.509 certificate. X.509 is a standard that defines the structure of the certificate. It defines the data fields that should be included in the SSL certificate. X.509 uses a formal language called Abstract Syntax Notation One (ASN.1) to express the certificate’s data structure.There are different formats of X.509 certificates such as PEM, DER, PKCS#7 and PKCS#12. PEM and PKCS#7 formats use Base64 ASCII encoding while DER and PKCS#12 use binary encoding. The certificate files have different extensions based on the format and encoding they use.PEM FormatMost CAs (Certificate Authority) provide certificates in PEM format in Base64 ASCII encoded files. The certificate file types can be .pem, .crt, .cer, or .key. The .pem file can include the server certificate, the intermediate certificate and the private key in a single file. The server certificate and intermediate certificate can also be in a separate .crt or .cer file. The private key can be in a .key file.PEM files use ASCII encoding, so you can open them in any text editor such as notepad, MS word etc. Each certificate in the PEM file is contained between the —- BEGIN CERTIFICATE—- and —-END CERTIFICATE—- statements. The private key is contained between the —- BEGIN RSA PRIVATE KEY—– and —–END RSA PRIVATE KEY—– statements. The CSR is contained between the —–BEGIN CERTIFICATE REQUEST—– and —–END CERTIFICATE REQUEST—– statements.PKCS#7 FormatThe PKCS#7 format is a Cryptographic Message Syntax Standard. The PKCS#7 certificate uses Base64 ASCII encoding with file extension .p7b or .p7c. Only certificates can be stored in this format, not private keys. The P7B certificates are contained between the “—–BEGIN PKCS7—–” and “—–END PKCS7—–” statements.DER FormatThe DER certificates are in binary form, contained in .der or .cer files. These certificates are mainly used in Java-based web servers.PKCS#12 FormatThe PKCS#12 certificates are in binary form, contained in .pfx or .p12 files.The PKCS#12 can store the server certificate, the intermediate certificate and the private key in a single .pfx file with password protection. These certificates are mainly used on the Windows platform.CAs provide certificates in any of the above formats." }, { "title": "7-Zip", "url": "/posts/tools-7-Zip/", "categories": "Tools", "tags": "tools, 7-zip", "date": "2020-09-01 16:00:00 +0200", "snippet": "GeneralFrom the official .chm file: 7z.exe is the command line version of 7-Zip. 7z.exe uses 7z.dll from the 7-Zip package. 7z.dll is used by the 7-Zip File Manager also. 7za.exe (a = alone) is a standalone version of 7-Zip. 7za.exe supports only 7z, xz, lzma, cab, zip, gzip, bzip2 and tar formats. 7za.exe doesn’t use external modules.Download needed versionCommand line usageBasic arguments: commands: add to archive: a extract with full paths: x switches: output: -o archive type: -t (ie. -t7z or -tzip) yes to all queries: -y exclude file: -x! (ie. \"-x!toto.txt\" or \"-x!*.txt\") Create an archiveExample, create a .7z archive with all the C:\\MyFolder\\* folder content excepted .7z, .zip and .json files and the Lib folder: 7za.exe \"a\" \"-t7z\" \"myArchive.7z\" \"C:\\MyFolder\\*\" \"-x!*.zip\" \"-x!*.7z\" \"-x!Lib\" \"-x!*.json\"Extract an archiveExample, extract the myArchive.7z to the C:\\MyFolder folder content excepted .7z, .zip and .json files and the Lib folder: 7za.exe \"a\" \"-t7z\" \"myArchive.7z\" \"-oC:\\MyFolder\"" }, { "title": "cURL", "url": "/posts/tools-cURL/", "categories": "Tools", "tags": "tools, curl, certificate", "date": "2020-09-01 10:00:00 +0200", "snippet": "cURL man pageWork with a client certificateUse a .p12 file as a client certificatecURL ... --cert-type P12 --cert myCertificate.p12cURL ... --cert-type P12 --cert myCertificate.p12:myPasswordUse a certificate from the Windows storeA cURL that works with WinSSL must be used!cURL ... --cert storeLocation\\storeName\\thumbprintExample:cURL ... --cert LocalMachine\\My\\969d0cacd0f76ec68e10feda75a28b58a1d54968Use separate client certificate, certification authority certificate and private key filesSee OpenSSL for details on the different filescURL ... --cert myClientCertificate.crt --key myPrivateKey.key --cacert myCaCert.crt " }, { "title": "certutil", "url": "/posts/tools-certutil/", "categories": "Tools", "tags": "tools, certutil, certificate", "date": "2020-09-01 09:00:00 +0200", "snippet": "Official documentationList certificates from given store name (default store location is local machine) The -store option belongs to store name The -user option enables to list the “current user” location instead of the “local machine” oneUseful to list certificates without mmc (or certmgr.msc) or to know, for example, if a certificate’s private key is exportable or not:certutil -store myOutput example:================ Certificate 1 ================Serial Number: 000abcf000000000000fIssuer: CN=Foo, DC=Bar, DC=Baz NotBefore: 10/9/2020 11:35 AM NotAfter: 10/8/2020 11:35 AMSubject: CN=TotoNon-root CertificateTemplate: 1.3.6.1.4.1.311.21.8.1276197.7416986.11292289.4105614.6793517.173.6633251.14043945Cert Hash(sha1): b4 b8 d3 89 b4 67 38 90 82 4d 33 d4 ea fd 48 d7 0f 2e 0d d8 Key Container = 15bd7cfb-834d-4fc7-1ab00abc49c6ec3 Provider = Microsoft Base Smart Card Crypto ProviderPrivate key is NOT exportableEncryption test passedConvert a base64 encoded pkcs12 certificate into a .p12 fileConsider the pkcs12 is contained in a pkcs12.txt file:certutil -decode pkcs12.txt irn-myCertificate.p12" }, { "title": "OpenSSL", "url": "/posts/tools-OpenSSL/", "categories": "Tools", "tags": "tools, openssl, certificate", "date": "2020-09-01 09:00:00 +0200", "snippet": "OpenSSL binariesSplit a .p12 file into three files private key (.key file) client certificate (.crt file) certification authority certificate (.crt file)openssl.exe pkcs12 -in C:\\input\\certificate.p12 -nocerts -out C:\\outputs\\privateKey.keyopenssl.exe pkcs12 -in C:\\input\\certificate.p12 -clcerts -nokeys -out C:\\outputs\\clientCertificate.crtopenssl.exe pkcs12 -in C:\\input\\certificate.p12 -cacerts -nokeys -out C:\\outputs\\caCertificate.crtConvert a base64 encoded pkcs12 certificate into a .p12 fileConsider the pkcs12 is contained in a pkcs12.txt file:openssl.exe base64 -d -a -in pkcs12.txt -out irn-myCertificate.p12Get all .p12 dataIt will display client certificate, CA certificate, private key, etc.:openssl.exe pkcs12 -info -in C:\\input\\certificate.p12 -nodesSourceGet public key from .p12Result is:openssl.exe pkcs12 -in C:\\input\\certificate.p12 -clcerts -nokeys -out C:\\outputs\\certificate.pem-----BEGIN CERTIFICATE-----...-----END CERTIFICATE-----Get private key from .p12Result is:openssl.exe pkcs12 -in C:\\input\\certificate.p12 -clcerts -nodes -out C:\\outputs\\certificate.key-----BEGIN PRIVATE KEY-----...-----END PRIVATE KEY-----" }, { "title": "Column operations", "url": "/posts/tsql-column-operations/", "categories": "Development, T-SQL", "tags": "development, t-sql, sqlserver, database, column", "date": "2020-09-01 09:00:00 +0200", "snippet": "Add a column to an existing tableALTER TABLE [MySchema].[MyTable]ADD [MyColumn] [bit] NULLGODrop a column from an existing table-- Don't forget to drop constraints first if neededALTER TABLE [MySchema].[MyTable]DROP COLUMN [MyColumn]GOExample: create a bit column that needs to be non nullable and to have a default 0 value-- The column needs to be nullable firstALTER TABLE [MySchema].[MyTable]ADD [MyColumn] [bit] NULLGOALTER TABLE [MySchema].[MyTable] ADD CONSTRAINT [DF_MyTable_MyColumn] DEFAULT ((0)) FOR [MyColumn]GO-- We set a default value for the existing rowsUPDATE [MySchema].[MyTable] SET [MyColumn] = 0GO-- And finally set the column non nullableALTER TABLE [MySchema].[MyTable]ALTER COLUMN [MyColumn] [bit] NOT NULLGOList a table/view columnsSimpliest way:SELECT * FROM INFORMATION_SCHEMA.COLUMNSMore complete way:SELECT OBJECT_SCHEMA_NAME(COLUMNS.[object_id]) AS [Schema name], OBJ.[name] AS [Table name], COLUMNS.[name] AS [Field name], TYP.[name] AS [Data type], TYP.[max_length] AS [Length size], TYP.[precision] AS PrecisionFROM sys.columns AS COLUMNS INNER JOIN sys.objects AS OBJ ON OBJ.[object_id] = COLUMNS.[object_id] LEFT JOIN sys.types AS TYP on TYP.[user_type_id] = COLUMNS.[user_type_id] WHERE -- U for a table, V for a view OBJ.[type] = 'V' " }, { "title": "Path operations", "url": "/posts/powershell-path-operations/", "categories": "Development, PowerShell", "tags": "development, powershell", "date": "2020-08-07 16:00:00 +0200", "snippet": "Joining two paths$basePath = 'C:\\foo'$firstChildPath = 'bar'$secondChildPath = 'baz'$fullPath = Join-Path $basePath -ChildPath $firstChildPath$pipedFullPath = Join-Path $basePath -ChildPath $firstChildPath | Join-Path -ChildPath $secondChildPath# fullPath is 'C:\\foo\\bar'# pipedFullPath is 'C:\\foo\\bar\\baz'Get parent path$fullPath = 'C:\\foo\\bar\\baz'$parentPath = Split-Path $fullPath -Parent$pipedParentPath = Split-Path $fullPath -Parent | Split-Path -Parent# parentPath is 'C:\\foo\\bar'# pipedParentPath is 'C:\\foo'Get leaf$fullPath = 'C:\\foo\\bar\\baz'$leaf = Split-Path $fullPath -Leaf# leaf is 'baz'Mix everything$fullPath = 'C:\\foo\\bar\\baz'$anotherLeaf = 'qux'$mixedPipedPath = Split-Path $fullPath -Parent | Join-Path -ChildPath $anotherLeaf# mixedPipedPath is 'C:\\foo\\bar\\qux'Check if a path exist or notWith the Test-Path cmdlet. To test its existence:if (Test-Path -Path 'myPath') { \"Path exists!\"}The contrary:if (!(Test-Path -Path 'myPath')) { \"Path does not exist!\"}Create a directoryWith the New-Item cmdlet:New-Item -ItemType Directory -Path 'myPath'" } ]
